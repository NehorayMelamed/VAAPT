

from Denoising_Basic_Layers import Color_Space_Conversion_Layer
from Memory_Networks import Get_Memory_Unit
#ESRGAN:
import ESRGAN_dataset
import ESRGAN_Visualizers
import ESRGAN_Optimizers
import ESRGAN_Losses
import ESRGAN_deep_utils
import ESRGAN_utils
import ESRGAN_Models
import ESRGAN_basic_Blocks_and_Layers
import ESRGAN_OPT
from ESRGAN_utils import *
from ESRGAN_deep_utils import *
from ESRGAN_basic_Blocks_and_Layers import *
from ESRGAN_Models import *
from ESRGAN_dataset import *
from ESRGAN_Losses import *
from ESRGAN_Optimizers import *
from ESRGAN_Visualizers import *
from ESRGAN_dataset import *
from ESRGAN_OPT import *


#os.environ["CUDA_VISIBLE_DEVICES"] = "0"


### Set Up Decices: ###
device0 = torch.device("cuda:0")
device1 = torch.device("cuda:1")
device_cpu = torch.device('cpu')



from pytorch_deform_conv.torch_deform_conv.layers import *
from pytorch_deform_conv_v2 import deform_conv_v2

import Denoising_Basic_Layers
from Denoising_Basic_Layers import *








#############################################################################################################################################################################################################################
###################################  UNet-Down:  ####################################

#TODO: add multiple heterogenous convolutions at the same layer level (similiar to Inception)
class UNET_Down_V1(nn.Module):

    def __init__(self,
                 number_of_input_channels_from_upper_layer,
                 number_of_output_channels,
                 kernel_sizes=3, strides=1, dilations=1, groups=1, normalization_function='instance_normalization', activation_function='prelu',
                 flag_max_pool=True):
        super(UNET_Down_V1, self).__init__()

        # Take Care Of Variables:
        if type(number_of_output_channels)!=list and type(number_of_output_channels)!=tuple:
            number_of_output_channels = [number_of_output_channels]
        number_of_layers = len(number_of_output_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers)
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)

        #Process Input From Upper Layer:
        self.conv1 = Sequential_Conv_Block(number_of_input_channels=number_of_input_channels_from_upper_layer,
                                           number_of_output_channels=number_of_output_channels,
                                           kernel_sizes=kernel_sizes,
                                           strides=strides,
                                           dilations=dilations,
                                           groups=groups,
                                           padding_type='reflect',
                                           normalization_function=normalization_function,
                                           activation_function=activation_function,
                                           mode='CNA')
        #DownSample Strategy:
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)

    def forward(self, output_before_maxpool):
        output_before_maxpool = self.conv1(output_before_maxpool)
        output_after_maxpool = self.maxpool1(output_before_maxpool)
        return output_before_maxpool, output_after_maxpool



class UNET_Down_Fusion_V1(nn.Module):
    #TODO: maybe add the possiblity of a "memory" which simply holds the previous output ???
    def __init__(self,
                 number_of_input_channels_from_upper_layer,
                 number_of_input_channels_from_cross_connection,
                 number_of_output_channels,
                 flag_use_cross_connection=True,
                 flag_Sequential_or_RDB = 'sequential', #'sequential' / 'rdb'
                 flag_sequential_resnet = False,
                 flag_sequential_concat = True,
                 kernel_sizes=3, strides=1, dilations=1, groups=1, normalization_function='instance_normalization', activation_function='prelu',
                 flag_downsample_strategy='maxpool',  #'maxpool' / 'unshuffle'
                 flag_add_unshuffled_input_to_lower_level=True):
        super(UNET_Down_Fusion_V1, self).__init__()

        # Take Care Of Variables:
        if type(number_of_output_channels)!=list and type(number_of_output_channels)!=tuple:
            number_of_output_channels = [number_of_output_channels]
        number_of_layers = len(number_of_output_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers)
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)

        self.flag_add_unshuffled_input_to_lower_level = flag_add_unshuffled_input_to_lower_level
        self.flag_use_cross_connection = flag_use_cross_connection;
        if flag_use_cross_connection==False:
            number_of_input_channels_from_cross_connection = 0;

        #Process Input From Upper Layer:
        if flag_Sequential_or_RDB == 'sequential':
            self.conv1 = Sequential_Conv_Block(number_of_input_channels=number_of_input_channels_from_upper_layer + number_of_input_channels_from_cross_connection,
                                               number_of_output_channels=number_of_output_channels,
                                               kernel_sizes=kernel_sizes,
                                               strides=strides,
                                               dilations=dilations,
                                               groups=groups,
                                               padding_type='reflect',
                                               normalization_function=normalization_function,
                                               activation_function=activation_function,
                                               mode='CNA',
                                               initialization_method='xavier',
                                               flag_resnet=flag_sequential_resnet,
                                               flag_concat=flag_sequential_concat)
        elif flag_Sequential_or_RDB == 'rdb':
            self.conv1 = RDB(number_of_input_channels=number_of_input_channels_from_upper_layer + number_of_input_channels_from_cross_connection,
                             number_of_output_channels_for_each_conv_block=number_of_output_channels,
                             number_of_conv_blocks=number_of_layers,
                             kernel_size=kernel_sizes, stride=1, bias=True, padding_type='reflect', normalization_function=None, activation_function='leakyrelu', mode='CNA',
                             final_residual_branch_scale_factor=1/number_of_layers)

        #DownSample Strategy:
        if flag_downsample_strategy == 'maxpool':
            self.downsample = nn.MaxPool2d(kernel_size=2)
        elif flag_downsample_strategy == 'unshuffle':
            self.downsample = UnshufflePixels(2); #less spatial extent more channels!!!!
        elif flag_downsample_strategy == 'simple_downsample':
            self.downsample = DownSample_Simple(2); #TODO: implement


    def forward(self, x, cross_connection_input=None):
        ### if there is a cross connection (or outside input) -> concat it to input: ###
        if self.flag_use_cross_connection and cross_connection_input!=None:
            output_before_maxpool = torch.cat([x, cross_connection_input])
        else:
            output_before_maxpool = x;

        ### Pass Forward through the layers: ###
        output_before_maxpool = self.conv1(output_before_maxpool)

        ### Prepare output to lower layer: ###
        output_after_maxpool = self.downsample(output_before_maxpool)
        if self.flag_add_unshuffled_input_to_lower_level:
            unshuffled_input = UnshufflePixels(x,2)
            output_after_maxpool = torch.cat([output_after_maxpool, unshuffled_input])

        return output_before_maxpool, output_after_maxpool


















class UNET_Down_Fusion_General_V1(nn.Module):
    #TODO: maybe add the possiblity of a "memory" which simply holds the previous output ???
    def __init__(self,
                 number_of_input_channels_from_upper_layer,
                 number_of_input_channels_from_cross_connection,
                 number_of_output_channels,
                 flag_use_final_projection_block = False,
                 number_of_output_channels_after_projection_block = 32,
                 flag_use_cross_connection=True,
                 flag_Sequential_or_RDB = 'sequential', #'sequential' / 'rdb'
                 flag_sequential_dense = False,
                 flag_sequential_resnet = False,
                 flag_sequential_concat = True,
                 stack_residual_scale = 1,
                 kernel_sizes=3, strides=1, dilations=1, groups=1,
                 normalization_function='instance_normalization',
                 activation_function='prelu',
                 initialization_method = 'dirac',
                 flag_downsample_strategy='maxpool',  #'maxpool' / 'unshuffle'
                 flag_add_unshuffled_input_to_lower_level=True,
                 ##############################################   --  1-K-1 --(*+)---
                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                 flag_SuperBlock_SFT=False,
                 flag_SuperBlock_SFT_use_outside_conditional=False,
                 flag_SuperBlock_SFT_same_on_all_channels=False,
                 flag_SuperBlock_SFT_base_convs_mix='x',  # 'x', 'y', 'xy'
                 flag_SuperBlock_SFT_SFT_convs_mix='x',  # 'x', 'y', 'xy'
                 flag_SuperBlock_SFT_add_y_to_output=False,
                 flag_SuperBlock_SFT_shift=False,
                 flag_SuperBlock_SFT_scale=False,
                 ### Deformable Convolution: ###
                 flag_deformable_convolution=False,
                 flag_deformable_convolution_version='v3',
                 flag_deformable_convolution_before_or_after_main_convolution='before',  # 'before' / 'after'
                 flag_deformable_convolution_modulation=True,
                 flag_deformable_kernel_size=5,
                 flag_deformable_number_of_deformable_groups=-1,
                 flag_deformable_number_of_channels_in_group1=-1,
                 flag_deformable_same_on_all_channels=True,
                 ### Deformable SFT: ###
                 flag_deformable_SFT_use_outside_conditional=False,
                 flag_deformable_SFT_same_on_all_channels=False,  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                 flag_deformable_SFT_base_convs_mix='x',
                 flag_deformable_SFT_SFT_convs_mix='x',
                 flag_deformable_SFT_shift=False,
                 flag_deformable_SFT_scale=False,
                 flag_deformable_SFT_add_y_to_output=False,
                 flag_deformable_for_each_sub_block_or_for_super_block='super_block',  # 'super_block' / 'sub_block'
                 #####################################
                 ### Cell and Super-Cell Types: ######
                 flag_single_cell_block_type='simple',  # 'simple'/ 'standard_residual'/ '131_residual'
                 flag_super_cell_block_type='131_collapse_residual', # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                 ):
        super(UNET_Down_Fusion_General_V1, self).__init__()




        # Take Care Of Variables:
        if type(number_of_output_channels)!=list and type(number_of_output_channels)!=tuple:
            number_of_output_channels = [number_of_output_channels]
        number_of_layers = len(number_of_output_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers)
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)

        self.flag_add_unshuffled_input_to_lower_level = flag_add_unshuffled_input_to_lower_level
        self.flag_use_cross_connection = flag_use_cross_connection;
        if flag_use_cross_connection==False:
            number_of_input_channels_from_cross_connection = 0;

        #Process Input From Upper Layer:
        if flag_Sequential_or_RDB == 'sequential':
            self.conv1 = Sequential_Conv_Block_General(number_of_input_channels=number_of_input_channels_from_upper_layer + number_of_input_channels_from_cross_connection,
                                               number_of_output_channels=number_of_output_channels,
                                               kernel_sizes=kernel_sizes,
                                               strides=strides,
                                               dilations=dilations,
                                               groups=groups,
                                               padding_type='reflect',
                                               normalization_function=normalization_function,
                                               activation_function=activation_function,
                                               mode='CNA',
                                               initialization_method=initialization_method,
                                               flag_dense=flag_sequential_dense,
                                               flag_resnet=flag_sequential_resnet,
                                               flag_concat=flag_sequential_concat,
                                               stack_residual_scale = stack_residual_scale,
                                               ##############################################   --  1-K-1 --(*+)---
                                               ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                               flag_SuperBlock_SFT=flag_SuperBlock_SFT,
                                               flag_SuperBlock_SFT_use_outside_conditional=flag_SuperBlock_SFT_use_outside_conditional,
                                               flag_SuperBlock_SFT_same_on_all_channels=flag_SuperBlock_SFT_same_on_all_channels,
                                               flag_SuperBlock_SFT_base_convs_mix=flag_SuperBlock_SFT_base_convs_mix,  # 'x', 'y', 'xy'
                                               flag_SuperBlock_SFT_SFT_convs_mix=flag_SuperBlock_SFT_SFT_convs_mix,  # 'x', 'y', 'xy'
                                               flag_SuperBlock_SFT_add_y_to_output=flag_SuperBlock_SFT_add_y_to_output,
                                               flag_SuperBlock_SFT_shift=flag_SuperBlock_SFT_shift,
                                               flag_SuperBlock_SFT_scale=flag_SuperBlock_SFT_scale,
                                               ### Deformable Convolution: ###
                                               flag_deformable_convolution=flag_deformable_convolution,
                                               flag_deformable_convolution_version=flag_deformable_convolution_version,
                                               flag_deformable_convolution_before_or_after_main_convolution=flag_deformable_convolution_before_or_after_main_convolution,  # 'before' / 'after'
                                               flag_deformable_convolution_modulation=flag_deformable_convolution_modulation,
                                               flag_deformable_kernel_size=flag_deformable_kernel_size,
                                               flag_deformable_number_of_deformable_groups=flag_deformable_number_of_deformable_groups,
                                               flag_deformable_number_of_channels_in_group1=flag_deformable_number_of_channels_in_group1,
                                               flag_deformable_same_on_all_channels=flag_deformable_same_on_all_channels,
                                               ### Deformable SFT: ###
                                               flag_deformable_SFT_use_outside_conditional=flag_deformable_SFT_use_outside_conditional,
                                               flag_deformable_SFT_same_on_all_channels=flag_deformable_SFT_same_on_all_channels,  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                               flag_deformable_SFT_base_convs_mix=flag_deformable_SFT_base_convs_mix,
                                               flag_deformable_SFT_SFT_convs_mix=flag_deformable_SFT_SFT_convs_mix,
                                               flag_deformable_SFT_shift=flag_deformable_SFT_shift,
                                               flag_deformable_SFT_scale=flag_deformable_SFT_scale,
                                               flag_deformable_SFT_add_y_to_output=flag_deformable_SFT_add_y_to_output,
                                               flag_deformable_for_each_sub_block_or_for_super_block=flag_deformable_for_each_sub_block_or_for_super_block,  # 'super_block' / 'sub_block'
                                               ### Cell & Super-Cell Types: ###
                                               flag_single_cell_block_type=flag_single_cell_block_type,
                                               flag_super_cell_block_type=flag_super_cell_block_type,
                                                       )
        elif flag_Sequential_or_RDB == 'rdb':
            self.conv1 = RDB(number_of_input_channels=number_of_input_channels_from_upper_layer + number_of_input_channels_from_cross_connection,
                             number_of_output_channels_for_each_conv_block=number_of_output_channels,
                             number_of_conv_blocks=number_of_layers,
                             kernel_size=kernel_sizes, stride=1, bias=True, padding_type='reflect', normalization_function=None, activation_function='leakyrelu', mode='CNA',
                             final_residual_branch_scale_factor=1/number_of_layers)


        ### Final Projection Block: ###
        if flag_use_final_projection_block:
            self.projection_block = Color_Space_Conversion_Layer(number_of_input_channels=self.conv1.final_number_of_channels,number_of_output_channels=number_of_output_channels_after_projection_block)
            self.conv1 = nn.Sequential(self.conv1, self.projection_block)
            self.final_number_of_channels = number_of_output_channels_after_projection_block
        else:
            self.final_number_of_channels = self.conv1.final_number_of_channels

        # if flag_sequential_concat:
        #     self.final_number_of_channels += number_of_input_channels_from_cross_connection + number_of_input_channels_from_upper_layer

        #DownSample Strategy:
        if flag_downsample_strategy == 'maxpool':
            self.downsample = nn.MaxPool2d(kernel_size=2)
        elif flag_downsample_strategy == 'unshuffle':
            self.downsample = UnshufflePixels(2); #less spatial extent more channels!!!!
        elif flag_downsample_strategy == 'simple_downsample':
            self.downsample = DownSample_Simple(2); #TODO: implement
        elif flag_downsample_strategy == 'DPP_learned':
            self.downsample = DPP_learned();
        elif flag_downsample_strategy == 'DPP':
            self.downsample = DPP();
        elif flag_downsample_strategy == 'avgpool':
            self.downsample = nn.AvgPool2d(kernel_size=2);


    def forward(self, x, outside_connection_input=None, y_cell_conditional=None, y_deformable_conditional=None):
        ### if there is a cross connection (or outside input) -> concat it to input: ###
        if self.flag_use_cross_connection and outside_connection_input is not None:
            output_before_maxpool = torch.cat([outside_connection_input, x], dim=1)
        else:
            output_before_maxpool = x;

        ### Pass Forward through the layers: ###
        # print('output_before_maxpool: ' + str(output_before_maxpool.shape))
        # print('down layer' + str(y_cell_conditional.shape))
        output_before_maxpool = self.conv1(output_before_maxpool, y_cell_conditional, y_deformable_conditional)

        ### Prepare output to lower layer: ###
        output_after_maxpool = self.downsample(output_before_maxpool)
        if self.flag_add_unshuffled_input_to_lower_level:
            unshuffled_input = UnshufflePixels(x,2)
            output_after_maxpool = torch.cat([output_after_maxpool, unshuffled_input], dim=1)

        return output_before_maxpool, output_after_maxpool









class UNET_Down_Memory_V1(nn.Module):
    def __init__(self,
                 memory_unit_name,
                 number_of_input_channels_from_upper_layer,
                 number_of_hidden_states_channels,
                 kernel_sizes=[3,3], strides=[1,1], dilations=[1,1], groups=[1,1],
                 normalization_function='instance_normalization',
                 activation_function='prelu',
                 flag_deformable_convolution=False):
        super(UNET_Down_Memory_V1, self).__init__()

        # Take Care Of Variables:
        if type(number_of_hidden_states_channels)!=list and type(number_of_hidden_states_channels)!=tuple:
            number_of_hidden_states_channels = [number_of_hidden_states_channels]
        number_of_layers = len(number_of_hidden_states_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers);
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)
        activation_function = to_list_of_certain_size(activation_function, number_of_layers)
        flag_deformable_convolution = to_list_of_certain_size(flag_deformable_convolution, number_of_layers)

        #Process Input From Upper Layer:
        self.ConvMemory = Get_Memory_Unit(memory_unit_name=memory_unit_name,
                                          input_size = number_of_input_channels_from_upper_layer,
                                          hidden_sizes=number_of_hidden_states_channels,
                                          n_layers=number_of_layers,
                                          kernel_sizes=kernel_sizes,
                                          strides=strides,
                                          dilations=dilations,
                                          groups=groups,
                                          normalization_function=normalization_function,
                                          activation_function = activation_function,
                                          flag_deformable_convolution=flag_deformable_convolution)


        #DownSample Strategy:
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)


    def reset_hidden_states(self):
        self.ConvMemory.reset_hidden_states()

    def reset_or_detach_hidden_states(self, reset_flags_list):
        self.ConvMemory.reset_or_detach_hidden_states(reset_flags_list)

    def hidden_states_to_device(self,device):
        self.ConvMemory.hidden_states_to_device(device);

    def forward(self, input_tensor,reset_flags_list):
        output_before_maxpool = self.ConvMemory(input_tensor,reset_flags_list)
        output_after_maxpool = self.maxpool1(output_before_maxpool)
        return output_before_maxpool, output_after_maxpool








class UNET_Down_GRU_V1(nn.Module):
    def __init__(self,
                 number_of_input_channels_from_upper_layer,
                 number_of_hidden_states_channels,
                 kernel_sizes=[3,3], strides=[1,1], dilations=[1,1], groups=[1,1], normalization_function='instance_normalization', activation_function='prelu', flag_deformable_convolution=False):
        super(UNET_Down_GRU_V1, self).__init__()

        # Take Care Of Variables:
        if type(number_of_hidden_states_channels)!=list and type(number_of_hidden_states_channels)!=tuple:
            number_of_hidden_states_channels = [number_of_hidden_states_channels]
        number_of_layers = len(number_of_hidden_states_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers);
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)
        flag_deformable_convolution = to_list_of_certain_size(flag_deformable_convolution, number_of_layers)

        #Process Input From Upper Layer:
        self.ConvGRU2D_1 = ConvGRU2D(input_size=number_of_input_channels_from_upper_layer,
                                     hidden_sizes=number_of_hidden_states_channels,
                                     n_layers=number_of_layers,
                                     kernel_sizes=kernel_sizes,
                                     strides=strides,
                                     dilations=dilations,
                                     groups=groups,
                                     normalization_function=normalization_function,
                                     flags_deformable_convolution=flag_deformable_convolution)

        #DownSample Strategy:
        self.maxpool1 = nn.MaxPool2d(kernel_size=2)


    def reset_hidden_states(self):
        self.ConvGRU2D_1.reset_hidden_states()

    def reset_or_detach_hidden_states(self, reset_flags_list):
        self.ConvGRU2D_1.reset_or_detach_hidden_states(reset_flags_list)

    def hidden_states_to_device(self,device):
        self.ConvGRU2D_1.hidden_states_to_device(device);

    def forward(self, input_tensor):
        output_before_maxpool = self.ConvGRU2D_1(input_tensor)
        output_after_maxpool = self.maxpool1(output_before_maxpool)
        return output_before_maxpool, output_after_maxpool
#########################################################################################################################################################################################################################################################################################################################################################










################################################################################################################################################################################################################################################################################################################################################################################
#####################################  UNet-Up:  ##################################
class UNET_Up_V1(nn.Module):
    def __init__(self,
                 number_of_lower_level_channels,
                 number_of_lower_level_channels_after_upsample,
                 number_of_cross_connection_channels,
                 number_of_output_channels,
                 flag_use_cross_connection=True,
                 flag_Sequential_or_RDB='sequential',  # 'sequential' / 'rdb'
                 flag_sequential_resnet=False,
                 flag_sequential_concat=False,
                 kernel_sizes=3, strides=1, dilations=1, groups=1, normalization_function='instance_normalization', activation_function='prelu',
                 flag_upsample_method='bilinear',
                 flag_add_unshuffled_input_to_upper_level=False,
                 initialization_method='xavier'):
        super(UNET_Up_V1, self).__init__()


        #Take Care Of Variables:
        if type(number_of_output_channels)!=list and type(number_of_output_channels)!=tuple:
            number_of_output_channels = [number_of_output_channels]
        number_of_layers = len(number_of_output_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers)
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)

        self.number_of_cross_connection_channels = number_of_cross_connection_channels;
        self.flag_use_cross_connection = flag_use_cross_connection;
        if flag_use_cross_connection==False:
            number_of_cross_connection_channels = 0;

        #(*). Upsample Method For Low Layer Input:
        if flag_upsample_method=='deconvolution' or 'transpose' in flag_upsample_method:
            self.up = nn.ConvTranspose2d(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample, kernel_size=2, stride=2)
        elif flag_upsample_method=='bilinear':
            self.up = nn.UpsamplingBilinear2d(scale_factor=2)
        elif 'pytorch_smart_shuffle' in flag_upsample_method:
            self.up = nn.PixelShuffle(upscale_factor=2)
        elif flag_upsample_method == 'my_smart_shuffle':
            self.up = Pixel_Shuffle_Block(number_of_lower_level_channels,
                                          number_of_lower_level_channels_after_upsample,
                                          upscale_factor=2,
                                          kernel_size=3, stride=1, bias=True, padding_type='zero',
                                          normalization_function=None,
                                          activation_function=activation_function)
        elif flag_upsample_method == 'my_smart_shuffle_stacked':
            self.up = Pixel_Shuffle_Block_Stacked(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample,
                                                  upscale_factor=2, number_of_layers = 2,
                                                  kernel_size=3, stride=1, bias=True, padding_type='zero', normalization_function=None, activation_function=activation_function)
        elif flag_upsample_method == 'simple_shuffle':
            self.up = ShufflePixels(2)


        ### If the upsampling method is using shuffle then the number of channels goes down by 4: ###
        self.flag_lower_level_shuffled = ('shuffle' in flag_upsample_method)
        if self.flag_lower_level_shuffled:
            number_of_lower_level_channels_after_upsample = int(number_of_lower_level_channels/4);


        #(*). Fusion Strategy (concat -> conv):
        if flag_Sequential_or_RDB == 'sequential':
            self.conv_block_on_fused_inputs = Sequential_Conv_Block(number_of_input_channels=number_of_lower_level_channels_after_upsample + number_of_cross_connection_channels,
                                               number_of_output_channels=number_of_output_channels,
                                               kernel_sizes=kernel_sizes,
                                               strides=strides,
                                               dilations=dilations,
                                               groups=groups,
                                               padding_type='reflect',
                                               normalization_function=normalization_function,
                                               activation_function=activation_function,
                                               mode='CNA',
                                               initialization_method=initialization_method,
                                               flag_resnet=flag_sequential_resnet,
                                               flag_concat=flag_sequential_concat)
        elif flag_Sequential_or_RDB == 'rdb':
            self.conv_block_on_fused_inputs = RDB(number_of_input_channels=number_of_input_channels_from_upper_layer + number_of_input_channels_from_cross_connection,
                             number_of_output_channels_for_each_conv_block=number_of_output_channels,
                             number_of_conv_blocks=number_of_layers,
                             kernel_size=kernel_sizes, stride=1, bias=True, padding_type='reflect', normalization_function=None, activation_function='leakyrelu', mode='CNA',
                             final_residual_branch_scale_factor=1/number_of_layers)


    def forward(self, input_cross_connection, input_low_layer):
        #(1). upsample input coming from lower layer:
        lower_level_upsampled = self.up(input_low_layer)

        if self.flag_use_cross_connection == False:
            ### No Cross Conection!: ###
            return self.conv_block_on_fused_inputs(lower_level_upsampled)
        else:
            ### With Cross Connection!: ###
            # Correct For cross connection and upsample layer output size discrepency:
            offset = input_cross_connection.size()[2] - lower_level_upsampled.size()[2]  # offset SHOULD BE either 0 or 1 (for instance downsampling from 25 to 12 and the upscaling from 12 to 24)
            padding = [offset, 0, offset, 0]
            lower_level_upsampled_padded = F.pad(lower_level_upsampled, padding, 'reflect')
            # Fuse Information by concatenating and convolving:
            return self.conv_block_on_fused_inputs(torch.cat([input_cross_connection, lower_level_upsampled_padded], 1))













class UNET_Up_General_V1(nn.Module):
    def __init__(self,
                 number_of_lower_level_channels,
                 number_of_lower_level_channels_after_upsample,
                 number_of_cross_connection_channels,
                 number_of_output_channels,
                 flag_use_final_projection_block=True,
                 number_of_output_channels_after_projection_block=32,
                 flag_use_cross_connection=True,
                 flag_Sequential_or_RDB='sequential',  # 'sequential' / 'rdb'
                 flag_sequential_dense=False,
                 flag_sequential_resnet=False,
                 flag_sequential_concat=False,
                 stack_residual_scale=1,
                 kernel_sizes=3, strides=1, dilations=1, groups=1, normalization_function='instance_normalization', activation_function='prelu',
                 flag_upsample_method='bilinear',
                 flag_add_unshuffled_input_to_upper_level=False,
                 initialization_method='xavier',
                 ##############################################   --  1-K-1 --(*+)---
                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                 flag_SuperBlock_SFT=False,
                 flag_SuperBlock_SFT_use_outside_conditional=False,
                 flag_SuperBlock_SFT_same_on_all_channels=False,
                 flag_SuperBlock_SFT_base_convs_mix='x',  # 'x', 'y', 'xy'
                 flag_SuperBlock_SFT_SFT_convs_mix='x',  # 'x', 'y', 'xy'
                 flag_SuperBlock_SFT_add_y_to_output=False,
                 flag_SuperBlock_SFT_shift=False,
                 flag_SuperBlock_SFT_scale=False,
                 ### Deformable Convolution: ###
                 flag_deformable_convolution=False,
                 flag_deformable_convolution_version='v3',
                 flag_deformable_convolution_before_or_after_main_convolution='before',  # 'before' / 'after'
                 flag_deformable_convolution_modulation=True,
                 flag_deformable_kernel_size=5,
                 flag_deformable_number_of_deformable_groups=-1,
                 flag_deformable_number_of_channels_in_group1=-1,
                 flag_deformable_same_on_all_channels=True,
                 ### Deformable SFT: ###
                 flag_deformable_SFT_use_outside_conditional=False,
                 flag_deformable_SFT_same_on_all_channels=False,  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                 flag_deformable_SFT_base_convs_mix='x',
                 flag_deformable_SFT_SFT_convs_mix='x',
                 flag_deformable_SFT_shift=False,
                 flag_deformable_SFT_scale=False,
                 flag_deformable_SFT_add_y_to_output=False,
                 flag_deformable_for_each_sub_block_or_for_super_block='super_block',  # 'super_block' / 'sub_block'
                 #####################################
                 flag_single_cell_block_type='simple',  # 'simple'/ 'standard_residual'/ '131_residual'
                 flag_super_cell_block_type='131_collapse_residual', # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                 ):
        super(UNET_Up_General_V1, self).__init__()


        #Take Care Of Variables:
        if type(number_of_output_channels)!=list and type(number_of_output_channels)!=tuple:
            number_of_output_channels = [number_of_output_channels]
        number_of_layers = len(number_of_output_channels);
        kernel_sizes = to_list_of_certain_size(kernel_sizes, number_of_layers)
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)

        self.number_of_cross_connection_channels = number_of_cross_connection_channels;
        self.flag_use_cross_connection = flag_use_cross_connection;
        if flag_use_cross_connection==False:
            number_of_cross_connection_channels = 0;

        #(*). Upsample Method For Low Layer Input:
        if flag_upsample_method=='deconvolution' or 'transpose' in flag_upsample_method:
            self.up = nn.ConvTranspose2d(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample, kernel_size=2, stride=2)
        elif flag_upsample_method=='bilinear':
            self.up = nn.UpsamplingBilinear2d(scale_factor=2)
        elif 'pytorch_smart_shuffle' in flag_upsample_method:
            self.up = nn.PixelShuffle(upscale_factor=2)
        elif flag_upsample_method == 'my_smart_shuffle':
            self.up = Pixel_Shuffle_Block(number_of_lower_level_channels,
                                          number_of_lower_level_channels_after_upsample,
                                          upscale_factor=2,
                                          kernel_size=3, stride=1, bias=True, padding_type='zero',
                                          normalization_function=None,
                                          activation_function=activation_function)
        elif flag_upsample_method == 'my_smart_shuffle_stacked':
            self.up = Pixel_Shuffle_Block_Stacked(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample,
                                                  upscale_factor=2, number_of_layers = 2,
                                                  kernel_size=3, stride=1, bias=True, padding_type='zero', normalization_function=None, activation_function=activation_function)
        elif flag_upsample_method == 'simple_shuffle':
            self.up = ShufflePixels(2)
        elif flag_upsample_method == 'none':
            self.up = Identity_Layer()


        ### If the upsampling method is using shuffle then the number of channels goes down by 4: ###
        self.flag_lower_level_shuffled = ('pytorch_smart_shuffle' in flag_upsample_method or 'simple_shuffle' in flag_upsample_method)
        if self.flag_lower_level_shuffled:
            number_of_lower_level_channels_after_upsample = int(number_of_lower_level_channels/4);


        #(*). Fusion Strategy (concat -> conv):
        if flag_Sequential_or_RDB == 'sequential':
            self.conv_block_on_fused_inputs = Sequential_Conv_Block_General(
                                              number_of_input_channels=number_of_lower_level_channels_after_upsample + number_of_cross_connection_channels,
                                               number_of_output_channels=number_of_output_channels,
                                               kernel_sizes=kernel_sizes,
                                               strides=strides,
                                               dilations=dilations,
                                               groups=groups,
                                               padding_type='reflect',
                                               normalization_function=normalization_function,
                                               activation_function=activation_function,
                                               mode='CNA',
                                               initialization_method=initialization_method,
                                               flag_dense=flag_sequential_dense,
                                               flag_resnet=flag_sequential_resnet,
                                               flag_concat=flag_sequential_concat,
                                               stack_residual_scale=stack_residual_scale,
                                               ##############################################   --  1-K-1 --(*+)---
                                               ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                               flag_SuperBlock_SFT=flag_SuperBlock_SFT,
                                               flag_SuperBlock_SFT_use_outside_conditional=flag_SuperBlock_SFT_use_outside_conditional,
                                               flag_SuperBlock_SFT_same_on_all_channels=flag_SuperBlock_SFT_same_on_all_channels,
                                               flag_SuperBlock_SFT_base_convs_mix=flag_SuperBlock_SFT_base_convs_mix,  # 'x', 'y', 'xy'
                                               flag_SuperBlock_SFT_SFT_convs_mix=flag_SuperBlock_SFT_SFT_convs_mix,  # 'x', 'y', 'xy'
                                               flag_SuperBlock_SFT_add_y_to_output=flag_SuperBlock_SFT_add_y_to_output,
                                               flag_SuperBlock_SFT_shift=flag_SuperBlock_SFT_shift,
                                               flag_SuperBlock_SFT_scale=flag_SuperBlock_SFT_scale,
                                               ### Deformable Convolution: ###
                                               flag_deformable_convolution=flag_deformable_convolution,
                                               flag_deformable_convolution_version=flag_deformable_convolution_version,
                                               flag_deformable_convolution_before_or_after_main_convolution=flag_deformable_convolution_before_or_after_main_convolution,  # 'before' / 'after'
                                               flag_deformable_convolution_modulation=flag_deformable_convolution_modulation,
                                               flag_deformable_kernel_size=flag_deformable_convolution_modulation,
                                               flag_deformable_number_of_deformable_groups=flag_deformable_number_of_deformable_groups,
                                               flag_deformable_number_of_channels_in_group1=flag_deformable_number_of_channels_in_group1,
                                               flag_deformable_same_on_all_channels=flag_deformable_same_on_all_channels,
                                               ### Deformable SFT: ###
                                               flag_deformable_SFT_use_outside_conditional=flag_deformable_SFT_use_outside_conditional,
                                               flag_deformable_SFT_same_on_all_channels=flag_deformable_SFT_same_on_all_channels,  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                               flag_deformable_SFT_base_convs_mix=flag_deformable_SFT_base_convs_mix,
                                               flag_deformable_SFT_SFT_convs_mix=flag_deformable_SFT_SFT_convs_mix,
                                               flag_deformable_SFT_shift=flag_deformable_SFT_shift,
                                               flag_deformable_SFT_scale=flag_deformable_SFT_scale,
                                               flag_deformable_SFT_add_y_to_output=flag_deformable_SFT_add_y_to_output,
                                               flag_deformable_for_each_sub_block_or_for_super_block=flag_deformable_for_each_sub_block_or_for_super_block,  # 'super_block' / 'sub_block'
                                               ### Cell & Super-Cell Types: ###
                                               flag_single_cell_block_type=flag_single_cell_block_type,
                                               flag_super_cell_block_type=flag_super_cell_block_type,
                                               )
        elif flag_Sequential_or_RDB == 'rdb':
            self.conv_block_on_fused_inputs = RDB(number_of_input_channels=number_of_input_channels_from_upper_layer + number_of_input_channels_from_cross_connection,
                             number_of_output_channels_for_each_conv_block=number_of_output_channels,
                             number_of_conv_blocks=number_of_layers,
                             kernel_size=kernel_sizes, stride=1, bias=True, padding_type='reflect', normalization_function=None, activation_function='leakyrelu', mode='CNA',
                             final_residual_branch_scale_factor=1/number_of_layers)

        ### Projection Block at the end: ###
        if flag_use_final_projection_block:
            self.projection_block = Color_Space_Conversion_Layer(number_of_input_channels=self.conv_block_on_fused_inputs.final_number_of_channels,
                                                                 number_of_output_channels=number_of_output_channels_after_projection_block)
            self.conv_block_on_fused_inputs = nn.Sequential(self.conv_block_on_fused_inputs, self.projection_block)
            self.final_number_of_channels = number_of_output_channels_after_projection_block
        else:
            self.final_number_of_channels = self.conv_block_on_fused_inputs.final_number_of_channels

        # if flag_sequential_concat:
        #     self.final_number_of_channels += number_of_lower_level_channels_after_upsample + number_of_cross_connection_channels


    def forward(self, input_cross_connection, input_low_layer, y_cell_conditional=None, y_deformable_conditional=None):
        #(1). upsample input coming from lower layer:
        lower_level_upsampled = self.up(input_low_layer)

        if self.flag_use_cross_connection == False:
            ### No Cross Conection!: ###
            return self.conv_block_on_fused_inputs(lower_level_upsampled, y_cell_conditional, y_deformable_conditional)
        else:
            ### With Cross Connection!: ###
            # Correct For cross connection and upsample layer output size discrepency:
            offset = input_cross_connection.size()[2] - lower_level_upsampled.size()[2]  # offset SHOULD BE either 0 or 1 (for instance downsampling from 25 to 12 and the upscaling from 12 to 24)
            padding = [offset, 0, offset, 0]
            lower_level_upsampled_padded = F.pad(lower_level_upsampled, padding, 'reflect')
            # Fuse Information by concatenating and convolving:
            return self.conv_block_on_fused_inputs(torch.cat([input_cross_connection, lower_level_upsampled_padded], 1), y_cell_conditional, y_deformable_conditional)










class UNET_Up_Memory_V1(nn.Module):
    def __init__(self,
                 memory_unit_name,
                 number_of_lower_level_channels,
                 number_of_lower_level_channels_after_upsample,
                 number_of_cross_connection_channels,
                 number_of_hidden_states_channels,
                 flag_use_cross_connection=True,
                 kernel_sizes=3, strides=1, dilations=1, groups=1, normalization_function='instance_normalization', flag_upsample_method='bilinear', flag_deformable_convolution=False,
                 activation_function='none'):
        super(UNET_Up_Memory_V1, self).__init__()

        # Take Care Of Variables:
        if type(kernel_sizes)!=list and type(kernel_sizes)!=tuple:
            kernel_sizes = [kernel_sizes]
        if type(number_of_hidden_states_channels)!=list and type(number_of_hidden_states_channels)!=tuple:
            number_of_hidden_states_channels = [number_of_hidden_states_channels]
        number_of_layers = len(kernel_sizes);
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)
        flag_deformable_convolution = to_list_of_certain_size(flag_deformable_convolution,number_of_layers)

        self.number_of_cross_connection_channels = number_of_cross_connection_channels;
        self.flag_use_cross_connection = flag_use_cross_connection

        #(*). Upsample Method For Low Layer Input:
        if flag_upsample_method=='deconvolution' or 'transpose' in flag_upsample_method:
            self.up = nn.ConvTranspose2d(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample, kernel_size=2, stride=2)
        elif flag_upsample_method=='bilinear':
            self.up = nn.UpsamplingBilinear2d(scale_factor=2)
        elif 'pytorch_smart_shuffle' in flag_upsample_method:
            self.up = nn.PixelShuffle(upscale_factor=2)
        elif flag_upsample_method == 'my_smart_shuffle':
            self.up = Pixel_Shuffle_Block(number_of_lower_level_channels,
                                          number_of_lower_level_channels_after_upsample,
                                          upscale_factor=2,
                                          kernel_size=3, stride=1, bias=True, padding_type='zero',
                                          normalization_function=None,
                                          activation_function=activation_function)
        elif flag_upsample_method == 'my_smart_shuffle_stacked':
            self.up = Pixel_Shuffle_Block_Stacked(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample,
                                                  upscale_factor=2, number_of_layers = 2,
                                                  kernel_size=3, stride=1, bias=True, padding_type='zero', normalization_function=None, activation_function=activation_function)
        elif flag_upsample_method == 'simple_shuffle':
            self.up = ShufflePixels(2)

        #(*). Fusion Strategy:
        #number_of_input_channels = number_of_lower_level_channels + number_of_cross_connection_channels
        self.conv_block_on_fused_inputs = Get_Memory_Unit(memory_unit_name = memory_unit_name,
                                                          input_size=number_of_lower_level_channels + number_of_cross_connection_channels,
                                                          hidden_sizes=number_of_hidden_states_channels,
                                                          n_layers=number_of_layers,
                                                          kernel_sizes=kernel_sizes,
                                                          strides=strides,
                                                          dilations=dilations,
                                                          groups=groups,
                                                          normalization_function=normalization_function,
                                                          flag_deformable_convolution=flag_deformable_convolution)


    def reset_hidden_states(self):
        self.conv_block_on_fused_inputs.reset_hidden_states()

    def reset_or_detach_hidden_states(self, reset_flags_list):
        self.conv_block_on_fused_inputs.reset_or_detach_hidden_states(reset_flags_list)


    def hidden_states_to_device(self,device):
        self.conv_block_on_fused_inputs.hidden_states_to_device(device);


    def forward(self, input_cross_connection, input_low_layer,reset_flags_list):
        # (1). upsample input coming from lower layer:
        lower_level_upsampled = self.up(input_low_layer)
        if self.flag_use_cross_connection == False:
            ### No Cross Conection!: ###
            return self.conv_block_on_fused_inputs(lower_level_upsampled_padded)
        else:
            ### With Cross Connection!: ###
            # Correct For cross connection and upsample layer output size discrepency:   TODO: this below assumes a rectangular shape...not necessarily true!!!!!!
            offset = input_cross_connection.size()[2] - lower_level_upsampled.size()[2]  # offset SHOULD BE either 0 or 1 (for instance downsampling from 25 to 12 and the upscaling from 12 to 24)
            padding = [offset, 0, offset, 0]
            lower_level_upsampled_padded = F.pad(lower_level_upsampled, padding, 'reflect')
            # Fuse Information by concatenating and convolving:
            return self.conv_block_on_fused_inputs(torch.cat([input_cross_connection, lower_level_upsampled_padded], 1),reset_flags_list)







class UNET_Up_GRU_V1(nn.Module):
    def __init__(self,
                 number_of_lower_level_channels,
                 number_of_lower_level_channels_after_upsample,
                 number_of_cross_connection_channels,
                 number_of_hidden_states_channels,
                 flag_use_cross_connection=True,
                 kernel_sizes=3, strides=1, dilations=1, groups=1, normalization_function='instance_normalization', flag_upsample_method='bilinear', flag_deformable_convolution=False):
        super(UNET_Up_GRU_V1, self).__init__()

        # Take Care Of Variables:
        if type(kernel_sizes)!=list and type(kernel_sizes)!=tuple:
            kernel_sizes = [kernel_sizes]
        if type(number_of_hidden_states_channels)!=list and type(number_of_hidden_states_channels)!=tuple:
            number_of_hidden_states_channels = [number_of_hidden_states_channels]
        number_of_layers = len(kernel_sizes);
        strides = to_list_of_certain_size(strides, number_of_layers)
        dilations = to_list_of_certain_size(dilations, number_of_layers)
        groups = to_list_of_certain_size(groups, number_of_layers)
        flag_deformable_convolution = to_list_of_certain_size(flag_deformable_convolution,number_of_layers)

        self.number_of_cross_connection_channels = number_of_cross_connection_channels;
        self.flag_use_cross_connection = flag_use_cross_connection

        #(*). Upsample Method For Low Layer Input:
        if flag_upsample_method=='deconvolution' or 'transpose' in flag_upsample_method:
            self.up = nn.ConvTranspose2d(number_of_lower_level_channels, number_of_lower_level_channels_after_upsample, kernel_size=2, stride=2)
        elif flag_upsample_method=='bilinear':
            self.up = nn.UpsamplingBilinear2d(scale_factor=2)
        elif 'smart_shuffle' in flag_upsample_method:
            self.up = nn.PixelShuffle(upscale_factor=2)
        elif 'simple_shuffle' in flag_upsample_method:
            self.up = ShufflePixels(2);

        #(*). Fusion Strategy:
        #number_of_input_channels = number_of_lower_level_channels + number_of_cross_connection_channels
        self.conv_block_on_fused_inputs = ConvGRU2D(input_size=number_of_lower_level_channels + number_of_cross_connection_channels,
                                                    hidden_sizes=number_of_hidden_states_channels,
                                                    n_layers=number_of_layers,
                                                    kernel_sizes=kernel_sizes,
                                                    strides=strides,
                                                    dilations=dilations,
                                                    groups=groups,
                                                    normalization_function=normalization_function,
                                                    flags_deformable_convolution=flag_deformable_convolution)


    def reset_hidden_states(self):
        self.conv_block_on_fused_inputs.reset_hidden_states()

    def reset_or_detach_hidden_states(self, reset_flags_list):
        self.conv_block_on_fused_inputs.reset_or_detach_hidden_states(reset_flags_list)


    def hidden_states_to_device(self,device):
        self.conv_block_on_fused_inputs.hidden_states_to_device(device);


    def forward(self, input_cross_connection, input_low_layer):
        # (1). upsample input coming from lower layer:
        lower_level_upsampled = self.up(input_low_layer)
        if self.flag_use_cross_connection == False:
            ### No Cross Conection!: ###
            return self.conv_block_on_fused_inputs(lower_level_upsampled_padded)
        else:
            ### With Cross Connection!: ###
            # Correct For cross connection and upsample layer output size discrepency:   TODO: this below assumes a rectangular shape...not necessarily true!!!!!!
            offset = input_cross_connection.size()[2] - lower_level_upsampled.size()[2]  # offset SHOULD BE either 0 or 1 (for instance downsampling from 25 to 12 and the upscaling from 12 to 24)
            padding = [offset, 0, offset, 0]
            lower_level_upsampled_padded = F.pad(lower_level_upsampled, padding, 'reflect')
            # Fuse Information by concatenating and convolving:
            return self.conv_block_on_fused_inputs(torch.cat([input_cross_connection, lower_level_upsampled_padded], 1))

#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################






















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V50(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V50, self).__init__()
        # (*). No skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). no previous intensity distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection =tvnet True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################



















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51, self).__init__()
        # (*). No skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################
















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51_V2(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51_V2, self).__init__()
        # (*). Yes skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()
        self.final_RGB_output_previous = decoder1
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################

















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51_V3(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51_V3, self).__init__()
        # (*). Yes skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()
        self.final_RGB_output_previous = decoder1
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################
















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51_V4(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51_V4, self).__init__()
        # (*). Yes skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). Yes SFT 'x' instead of residual

        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, True, True],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, True, True],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[True, True, True],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, True, True],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, True, True],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()
        self.final_RGB_output_previous = decoder1
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################
















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51_V5(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51_V5, self).__init__()
        # (*). Yes skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). Yes SFT 'x' instead of residual

        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[True, True, True],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[True, True, True],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[True, True, True],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[True, True, True],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()
        self.final_RGB_output_previous = decoder1
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################






















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51_V6(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51_V6, self).__init__()
        # (*). Yes skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). Yes SFT 'x' instead of residual

        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[False, False, False],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[True, True, True],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[False, False, False],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[True, True, True],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[False, False, False],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[True, True, True],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[False, False, False],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[True, True, True],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[False, False, False],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()
        self.final_RGB_output_previous = decoder1
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################




















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V51_V7(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V51_V7, self).__init__()
        # (*). Yes skip connection
        # (*). no center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). Yes SFT 'x' instead of residual

        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, True],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[3, 3, 3],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[False, False, False],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, True, True],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[3, 3, 3],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[False, False, False],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, True, True],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[3, 3, 3],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[False, False, False],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, True, True],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[3, 3, 3],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[False, False, False],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['x','x','x'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, True, True],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[3, 3, 3],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[False, False, False],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()
        self.final_RGB_output_previous = decoder1
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################

















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V52(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V52, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). no center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################





















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V53(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V53, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). Yes center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = True
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = True
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = True
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = True
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################




















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V54(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V54, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). No previous intensity distribution
        # (*). Yes RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[True, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, self.final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        ### Previous Intensity As Conditional: ###
        y_cell_conditional_input_level1 = final_RGB_output_previous
        y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output,x],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### NO Conditionals: ###
        # y_cell_conditional_input_level1 = None
        # y_cell_conditional_input_level2 = None
        # y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################






























####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V55(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V55, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). No previous intensity distribution
        # (*). Yes RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). Yes PCD->TSA output as conditional (TODO: later on maybe as input?)


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels= self.PCD_number_of_output_channels * 2,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[True, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        #(2). TSA Module:
        TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        ### Use TSA Output As Conditionals: ###
        y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### NO Conditionals: ###
        # y_cell_conditional_input_level1 = None
        # y_cell_conditional_input_level2 = None
        # y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################


















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V56(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V56, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). No previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). Yes Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[True, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### Use Conditional Network as feature extractors: ###
        y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### NO Conditionals: ###
        # y_cell_conditional_input_level1 = None
        # y_cell_conditional_input_level2 = None
        # y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################



















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V56_V2(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V56_V2, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). No previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). Yes Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[True, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### Use Conditional Network as feature extractors: ###
        y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### NO Conditionals: ###
        # y_cell_conditional_input_level1 = None
        # y_cell_conditional_input_level2 = None
        # y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################




















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V57(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V57, self).__init__()
        #(*). Only insert final output to input

        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )
        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3],
                                                                   kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect',
                                                                   normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier',
                                                                   flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,
                                                                   ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False],
                                                                   flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                                   flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                                   flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                                   flag_SuperBlock_SFT_shift=[True, True, True],
                                                                   flag_SuperBlock_SFT_scale=[True, True, True],
                                                                   ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False],
                                                                   flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                                   flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False],
                                                                   flag_deformable_kernel_size=[5, 5, 5],
                                                                   flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                                   flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                                   flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                                   flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                                   flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                                   flag_deformable_SFT_shift=[False, False, False],
                                                                   flag_deformable_SFT_scale=[False, False, False],
                                                                   flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                                   flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                                   flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[True, True, True],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[True, True, True],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################































####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V58(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V58, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). Yes center previous state distribution
        # (*). No previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). Yes input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[True, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[True, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[True, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        ### SFT is residual between current and last output: ###
        y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### NO Conditionals: ###
        # y_cell_conditional_input_level1 = None
        # y_cell_conditional_input_level2 = None
        # y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################


















####  Sequential Block @ Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V59(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V59, self).__init__()
        # (*). Yes skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). No previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). no Running Average (RA) at center
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################






















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V60(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V60, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). YES Running Average (RA) at center On RAW PIXELS and only distributing to decoder
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = True
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = True
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = True
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = True
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RGB Input Running Average (TODO: implement with only intensity): ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RuingAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################



















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V60_V0(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V60_V0, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). YES Running Average (RA) at center On RAW PIXELS and only distributing to decoder
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = True
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RGB Input Running Average (TODO: implement with only intensity): ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V60_V2(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V60_V2, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). YES Running Average (RA) at center On RAW PIXELS and only distributing to decoder
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = True
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = True
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = True
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RGB Input Running Average (TODO: implement with only intensity): ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################
















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V61(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V61, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = False
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**2)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RunningAverageFeatures_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RunningAverageFeatures_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################



















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V61_V3(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V61_V3, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = False
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**2)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RunningAverageFeatures_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RunningAverageFeatures_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        combined_center_RNN_output = self.center_features_RunningAverage(combined_center_RNN_output)
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        # #### Running Average On Features: ###
        # center_RunningAverage_features_input = maxpool2;
        # if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
        #     center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        # center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        # center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        # center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################


















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V61_V0(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V61_V0, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = False
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**2)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RunningAverageFeatures_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RunningAverageFeatures_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################

























####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V61_V2(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V61_V2, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###  NOTE: this is a purely RGB RunningAverage...no room for any other input except maybe as conditionals to the reset gate
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = True
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**2)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = True
        self.flag_up2_get_RunningAverageFeatures_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = True
        self.flag_up1_get_center_RunningAverageFeatures_current = True
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################























####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V62(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V62, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). YES Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = True
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = True
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###  NOTE: this is a purely RGB RunningAverage...no room for any other input except maybe as conditionals to the reset gate
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = True
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**2)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = True
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = True
        self.flag_up2_get_RunningAverageFeatures_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = True
        self.flag_up1_get_center_RunningAverageFeatures_current = True
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################




















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V62_V2(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V62_V2, self).__init__()
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). YES Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = True
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = True
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###  NOTE: this is a purely RGB RunningAverage...no room for any other input except maybe as conditionals to the reset gate
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = True
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**2)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = True
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = True
        self.flag_up2_get_RunningAverageFeatures_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = True
        self.flag_up1_get_center_RunningAverageFeatures_current = True
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = nn.AvgPool2d(2)
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################






























### TVNET IMPORTS: ###
from TVnet_simple.data.frame_dataset import frame_dataset
from TVnet_simple.train_options import arguments
import torch.utils.data as data
from TVnet_simple.model.network_tvnet import model
import scipy.io as sio
from TVnet_simple.utils import *
device0 = torch.device("cuda:0")
device1 = torch.device("cuda:1")
device_cpu = torch.device('cpu')

### Default Options For TVNet: ###
import easydict
from easydict import EasyDict

### Function Returning TVNet Module Instance: ###
def get_TVNet_instance(x_input, number_of_iterations=60, number_of_pyramid_scales=3, device=device1, flag_trainable=False):
    args = EasyDict()
    args.frame_dir = 'blabla' #path to frames
    args.img_save_dir = 'blabla' #path to storage generated feature maps if needed
    args.n_epocs = 100
    args.n_threads = 1
    args.batch_size = 1;
    args.learning_rate = 1e-4
    args.is_shuffle = False
    args.visualize = False
    # args.data_size = (100,100); #TODO: understand the needed format here!$#@%
    args.zfactor = 0.5 #factor for building the image pyramid
    args.max_nscale = number_of_pyramid_scales; #max number of scales for image pyramid
    args.n_warps = 1; #number of warping per scale
    args.n_iters = number_of_iterations; #max number of iterations for optimization
    args.demo = False;
    ## Don't Change according to moran: ###
    args.tau = 0.25; #time step
    args.lbda = 0.1; #weight parameter for the data term
    args.theta = 0.3; #weight parameter for (u-v)^2

    ### Get default arguments: ###
    B,C,H,W = x_input.shape
    args.batch_size = B # KILL
    args.demo = False
    args.data_size = [B, C, H, W]
    args.device = x_input.device

    ### Initialize TVNet from model function: ###
    Network = model(args).to(args.device)
    if flag_trainable==False:
        Network = Network.eval()
        for param in Network.parameters():
            param.requires_grad = False

    return Network




















######################################################################################################################################################################################################################################################################################################################
class UNET_V31_V1(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V31_V1, self).__init__()
        #(*). No Running Average!!!
        #(*). ENTER DEFORMABLE CONVOLUTIONS!
        #(*). Possible Activation Functions: 'relu', 'leakyrelu', 'double_relu', 'sigmoid', 'none', 'swish_torch', 'diode_torch', 'normal_torch',
        #                                    'normal_derivative_torch', 'normal_derivative_modified_torch', 'normal_modified_torch', 'diode_torch_PositivityByExp', 'diode_torch_PositivityByAbs', 'diode_torch_OnlyCentersLearned', 'learnable_amplitude'


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)


        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = True;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RNN_previous = True;
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=[1, 1, 1], dilations=[[1, 2, 4], [1, 2, 4]], groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 flag_deformable_convolution=[False, False, True],
                                                 flag_deformable_convolution_version=['v1', 'v1', 'v1'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 flag_deformable_for_each_sub_block_or_for_super_block='super_block',  # 'super_block' / 'sub_block'
                                                 flag_deformable_same_on_all_channels=[True,True,True] )



        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = True
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_RawInputExplicit = True
        self.flag_down2_get_center_RNN_previous = True
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 4
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 4
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 4
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=[1, 1], dilations=[[1, 2, 4], [1, 2, 4]], groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v1', 'v1', 'v1'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 flag_deformable_for_each_sub_block_or_for_super_block='super_block',  # 'super_block' / 'sub_block'
                                                 flag_deformable_same_on_all_channels=[True,True,True] )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**2);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**2)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 2)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = True
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = True
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**2)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
        self.center_RNN = Get_Memory_Unit(memory_unit_name=memory_unit_name,
                                      input_size=self.center_RNN_number_of_input_channels,  # 2 is the number of layers
                                      hidden_sizes=hidden_sizes_Center,
                                      n_layers=len(hidden_sizes_Center),
                                      kernel_sizes=[5, 5, 5], strides=1, dilations=1, groups=1,
                                      normalization_function=normalization_function,
                                      activation_function=activation_function,
                                      initialization_method='xavier',
                                      flag_deformable_convolution=[False, False, False],
                                      flag_deformable_convolution_version=['v1', 'v1', 'v1'],
                                      flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],
                                      flag_deformable_convolution_modulation=[False, False, True],
                                      flag_deformable_same_on_all_channels=[True, True, True])

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)
        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_get_RGBRunningAverage_current = True
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_final_RGB_previous = True #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = True
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = True
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = self.down2.final_number_of_channels;
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**2)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v1', 'v1', 'v1'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],
                                             flag_deformable_convolution_modulation=[False, False, True],
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             flag_deformable_for_each_sub_block_or_for_super_block='super_block',  # 'super_block' / 'sub_block'
                                             flag_deformable_same_on_all_channels=[True,True,True])



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_get_center_RNN_previous = True
        self.flag_up1_get_center_RNN_current = True
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = True
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = True
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = self.down1.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**1)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='bilinear',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             flag_deformable_convolution = [False,False,False],
                                             flag_deformable_convolution_version = ['v1','v1','v1'],
                                             flag_deformable_convolution_before_or_after_main_convolution = ['before','before','before'],
                                             flag_deformable_convolution_modulation = [False,False,False],
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             flag_deformable_for_each_sub_block_or_for_super_block='super_block',  # 'super_block' / 'sub_block'
                                             flag_deformable_same_on_all_channels=[True,True,True])

        self.unshuffle1 = UnshufflePixels(2);
        self.unshuffle2 = UnshufflePixels(4);
        self.shuffle1 = ShufflePixels(2);
        self.shuffle2 = ShufflePixels(4);
        self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[2]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);

        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped


        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous.detach()
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)



        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection)


        ### Encoder2: ###
        encoder2_input = maxpool1;
        encoder2_outside_connection = None
        # self.flag_down2_get_final_RGB_previous = True
        # self.flag_down2_get_center_RGB_RunningAverage_previous = True
        # self.flag_down2_get_RawInputExplicit = True
        # self.flag_down2_get_center_RNN_previous = True
        ###
        # encoder2_input = torch.cat([maxpool1, final_RGB_output_previous_unshuffled1, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)  # regular input = encoder1 output + running_average
        # encoder2_outside_connection = torch.cat([unshuffled_input1, center_RNN_output_to_encoder_previous_upsampled1], dim=1)  # outside_connection = raw unshuffled RGB input + lstm_output
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        #       (2.1.2). LSTM:
        center_RNN_input = maxpool2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current
        #   (2.4). Upsample Current RNN Outputs:
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = encoder2;
        ###
        # self.flag_up2_get_RGBRunningAverage_current = True
        # self.flag_up2_get_RGBRunningAverage_previous = False
        # self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        # self.flag_up2_get_final_RGB_previous = True  # TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        # self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        # self.flag_up2_get_center_RNN_previous = True
        # self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        # self.flag_up2_get_RAW_RGB_current = False
        # self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ###
        # decoder2_lstm_inputs = torch.cat([center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        # decoder2_running_average_inputs = torch.cat([center_RGB_RunningAverage_output_shuffled1], dim=1)  # TODO: wait what?....do i really need to input current & previous RGB_RunningAverage?!?!?!
        # decoder2_previous_final_RGB_input = final_RGB_output_previous_unshuffled1
        # decoder2_direct_input = torch.cat([center_RNN_output_to_decoder_current], dim=1)
        # decoder2_cross_connection = torch.cat([encoder2, decoder2_running_average_inputs, decoder2_lstm_inputs, decoder2_previous_final_RGB_input], dim=1)  # Maybe also insert RAW RGB input directly from the start??....similar to the logic of dense block?
        # decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_direct_input)  # (*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input) #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = encoder1
        ###
        # self.flag_up1_get_center_RNN_previous = True
        # self.flag_up1_get_center_RNN_current = True
        # self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        # self.flag_up1_get_center_RGBRunningAverage_previous = False
        # self.flag_up1_get_center_RGBRunningAverage_current = True
        # self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        # self.flag_up1_get_final_RGB_previous = True
        # self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        # self.flag_up1_get_RAW_RGB_current = False
        # self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ###
        # decoder1_lstm_inputs = torch.cat([center_RNN_output_to_decoder_upsampled2, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        # decoder1_running_average_inputs = torch.cat([center_RGB_RunningAverage_output_shuffled2], dim=1)  # TODO: wait what?....do i really need to input current & previous RGB_RunningAverage?!?!?!
        # decoder1_previous_final_RGB_input = final_RGB_output_previous
        # decoder1_cross_connection = torch.cat([encoder1, decoder1_running_average_inputs, decoder1_lstm_inputs, decoder1_previous_final_RGB_input], dim=1)
        # decoder1_direct_input = torch.cat([decoder2], dim=1)
        # decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_direct_input)
        ### Allocate number of channels: ###
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input)


        ### Assign Final Output (Detached for now!!!): ###
        self.final_RGB_output_previous = decoder1.detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################










































####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V70(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V70, self).__init__()
        ### No DownSampling ### #TODO: Implement increasing receptive field
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )


        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 1
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 1
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 1
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 1
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**0);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**0)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = False
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**0)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 0)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**0)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**0)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RunningAverageFeatures_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**0)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='none',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RunningAverageFeatures_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='none',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        # self.unshuffle1 = UnshufflePixels(2);
        # self.unshuffle2 = UnshufflePixels(4);
        # self.shuffle1 = ShufflePixels(2);
        # self.shuffle2 = ShufflePixels(4);
        # self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        # self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)
        self.upsample1 = Identity_Layer()  #No change in sizes
        self.upsample2 = Identity_Layer()  #No change in sizes
        self.unshuffle1 = Identity_Layer()
        self.unshuffle2 = Identity_Layer()
        self.shuffle1 = Identity_Layer()
        self.shuffle2 = Identity_Layer()

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = Identity_Layer()  #No change in sizes
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = encoder1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = encoder2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()  #NOTICE: I DELETED .detach()
        self.final_RGB_output_previous = decoder1  #NOTICE: I DELETED .detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################


















####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V70_V2(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V70_V2, self).__init__()
        ### No DownSampling ### #TODO: Implement increasing receptive field
        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )


        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 1
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 1
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 1
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 1
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**0);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**0)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = False
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**0)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 0)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**0)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**0)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RunningAverageFeatures_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**0)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='none',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RunningAverageFeatures_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='none',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        # self.unshuffle1 = UnshufflePixels(2);
        # self.unshuffle2 = UnshufflePixels(4);
        # self.shuffle1 = ShufflePixels(2);
        # self.shuffle2 = ShufflePixels(4);
        # self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        # self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)
        self.upsample1 = Identity_Layer()  #No change in sizes
        self.upsample2 = Identity_Layer()  #No change in sizes
        self.unshuffle1 = Identity_Layer()
        self.unshuffle2 = Identity_Layer()
        self.shuffle1 = Identity_Layer()
        self.shuffle2 = Identity_Layer()

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = Identity_Layer()  #No change in sizes
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = encoder1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = encoder2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        combined_center_RNN_output = self.center_features_RunningAverage(combined_center_RNN_output)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()  #NOTICE: I DELETED .detach()
        self.final_RGB_output_previous = decoder1  #NOTICE: I DELETED .detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################



























####  Sequential Block @ Center + RA # Center: ####
######################################################################################################################################################################################################################################################################################################################
class UNET_V71(nn.Module):
    def __init__(self, memory_unit_name='gru', activation_function_input='leakyrelu'):
        super(UNET_V71, self).__init__()
        ### No DownSampling ###
        ### Increasing Dilation/Receptive-Field: ###

        # (*). No skip connection
        # (*). Yes center distribution
        # (*). No center previous state distribution
        # (*). Yes previous intensity distribution
        # (*). No RAW previous intensity SFT whole network with 'y' interaction (still no learnable_amplitude conv layers so maybe not as effective...to be determined)
        # (*). No input and output intensity residual (x-y)^2 as residual
        # (*). Yes Input distribution
        # (*). no warping of previous state
        # (*). no SFT / y_conditionals
        # (*). no deformable convolution
        # (*). no RNN at center (Sequential)
        # (*). No Running Average (RA) at center On RAW PIXELS
        # (*). YES Running Average (RA) at center On Features
        # (*). No PCD on input and output  output as conditional (TODO: later on maybe as input?)
        # (*). No Conditional Network on input and previous_output as SFT


        # Parameters:
        # activation_function = 'leakyrelu';
        activation_function = activation_function_input;
        normalization_function = None;
        final_activation_function = 'none'
        channel_factor = 1;

        ### Flags: ###
        self.flag_input_raw_intensity_instead_of_rgb = True;
        self.UNET_Residual = False


        ### Optical Flow Module: ###
        self.TVNet_number_of_iterations = 30;
        self.TVNet_number_of_pyramid_scales = 4;
        self.TVNet_layer = None
        self.delta_x = None
        self.delta_y = None
        self.confidence = None #==RA update gate?


        ### Pre-Encoder: ###
        Initial_CCL_number_of_output_channels = 3; # RGB + Intensity
        self.Color_Conversion_Layer = Color_Space_Conversion_Layer(3, Initial_CCL_number_of_output_channels)

        ### PCD_Extract_and_Align Module To Extract Features From Input_RGB and Previous_Clean_Final_RGB and align them!: ###
        #TODO: maybe later also add TSA Module!
        self.PCD_number_of_output_channels = 6;
        self.PCD_number_of_feature_channels = 16
        self.PCD_Extract_and_Align_Module = PCD_Extract_and_Align(number_of_input_channels=1, #accept intensity
                                                                  number_of_feature_channels=self.PCD_number_of_feature_channels,
                                                                  number_of_output_channels=self.PCD_number_of_output_channels,
                                                                  flag_deformable_convolution_type='v3',
                                                                  number_of_deformable_groups=1)

        ### TSA Module: ###
        reference_reference_frame_index = 1;
        number_of_frames_compared = 2; #only current and previous...maybe later on i can save several Intensity Only backward frames
        self.TSA_Fusion_Module = TSA_Fusion(nf=self.PCD_number_of_output_channels, nframes=number_of_frames_compared, center=reference_reference_frame_index)


        ### SFT Conditionals Small Net: ###
        self.Conditionals_Network = Sequential_Conv_Block_General(
                                                        number_of_input_channels=1,  #Only Intensity For Each Feature Seperately
                                                        number_of_output_channels=[3, 3, 3],
                                                        kernel_sizes=[[3], [3], [3]],
                                                        strides=1,
                                                        dilations=[[1], [1], [1]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[False, False, False],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[True, True, True],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        self.Conditionals_Network2 = Sequential_Conv_Block_General(number_of_input_channels=6,  # Only Intensity For Each Feature Seperately
                                                                  number_of_output_channels=[3, 3, 3], kernel_sizes=[[3], [3], [3]], strides=1, dilations=[[1], [1], [1]], groups=1, padding_type='reflect', normalization_function=normalization_function, activation_function=activation_function, mode='CNA', initialization_method='xavier', flag_dense=False, flag_resnet=True, flag_concat=False, stack_residual_scale=1,  ##############################################   --  1-K-1 --(*+)---
                                                                  ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                                  flag_SuperBlock_SFT=[False, False, False], flag_SuperBlock_SFT_use_outside_conditional=[False, False, False], flag_SuperBlock_SFT_same_on_all_channels=[False, False, False], flag_SuperBlock_SFT_base_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_SFT_convs_mix=['x', 'x', 'x'],  # 'x', 'y', 'xy'
                                                                  flag_SuperBlock_SFT_add_y_to_output=[False, False, False], flag_SuperBlock_SFT_shift=[True, True, True], flag_SuperBlock_SFT_scale=[True, True, True],  ### Deformable Convolution: ###
                                                                  flag_deformable_convolution=[False, False, False], flag_deformable_convolution_version=['v3', 'v3', 'v3'], flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                                  flag_deformable_convolution_modulation=[False, False, False], flag_deformable_kernel_size=[5, 5, 5], flag_deformable_number_of_deformable_groups=[-1, -1, -1], flag_deformable_number_of_channels_in_group1=[-1, -1, -1], flag_deformable_same_on_all_channels=[True, True, True],  ### Deformable SFT: ###
                                                                  flag_deformable_SFT_use_outside_conditional=[False, False, False], flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                                  flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'], flag_deformable_SFT_shift=[False, False, False], flag_deformable_SFT_scale=[False, False, False], flag_deformable_SFT_add_y_to_output=[False, False, False], flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                                  #####################################
                                                                  flag_single_cell_block_type=['simple', 'simple', 'simple'], flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], )

        ###########################################################################################################################################################
        #### Encoder1: ####
        ### Number of Channels: ###
        final_RGB_previous_number_of_channels = 3
        if self.flag_input_raw_intensity_instead_of_rgb:
            final_RGB_previous_number_of_channels = 1;
        RGB_input_RunningAverage_number_of_channels = 3;
        RGB_input_number_of_channels = 3
        self.number_of_channels_LSTM_CCL_to_encoder_next_time = 10;
        number_of_channels_Encoder1 = [3 * 4 * channel_factor, 3 * 4 * channel_factor]
        ### number of channels temp variables: ###
        input_from_upper_level_number_of_channels_Encoder1 = Initial_CCL_number_of_output_channels;
        output_number_of_channels_Encoder1 = number_of_channels_Encoder1[-1]
        number_of_channels_from_running_average_ouside_input_Encoder1 = Initial_CCL_number_of_output_channels;
        ### Flags: ###
        #TODO: divide to direct_input & outside_connections
        self.flag_down1_use_outside_connection = True;
        self.flag_down1_get_final_RGB_previous = False;
        self.flag_down1_get_center_RGB_RunningAverage_previous = False
        self.flag_down1_get_center_RGB_RunningAverage_current = False
        self.flag_down1_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        # (1). From Upper Level:
        down1_number_of_input_channels_from_upper_layer = RGB_input_number_of_channels;
        # (2). From Outside:
        down1_number_of_input_channels_from_outside = 0;
        if self.flag_down1_get_final_RGB_previous:
            down1_number_of_input_channels_from_outside += final_RGB_previous_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            down1_number_of_input_channels_from_outside += RGB_input_RunningAverage_number_of_channels
        if self.flag_down1_get_center_RNN_previous:
            down1_number_of_input_channels_from_outside += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        self.down1_number_of_input_channels_from_outside = down1_number_of_input_channels_from_outside
        ### Define down1: ###
        self.down1_cross_connection_projection = Color_Space_Conversion_Layer(12,3)
        self.down1 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down1_number_of_input_channels_from_upper_layer, #raw input + raw_input_running_average
                                                 number_of_input_channels_from_cross_connection=down1_number_of_input_channels_from_outside,  #channels_from_center
                                                 number_of_output_channels=number_of_channels_Encoder1,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=number_of_channels_Encoder1[-1],
                                                 flag_use_cross_connection=self.flag_down1_use_outside_connection,  #TODO: for now i'm not using previous RNN & RA center outputs!!!$@#$
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 stack_residual_scale=1,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1, 1],
                                                 dilations=[[1, 2, 4], [1, 2, 4]],
                                                 groups=[1,1,1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',  # DPP_learned
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y','y','y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5,5,5],
                                                 flag_deformable_number_of_deformable_groups=[-1,-1,-1],
                                                 flag_deformable_number_of_channels_in_group1=[-1,-1,-1],
                                                 flag_deformable_same_on_all_channels=[True,True,True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x','x','x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block','super_block','super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type = ['simple','simple'], # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type = ['131_collapse','131_collapse'],# 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )


        #### Encoder2: ####
        # input_from_upper_level_number_of_channels_Encoder2 = output_number_of_channels_Encoder1
        input_from_upper_level_number_of_channels_Encoder2 = self.down1.final_number_of_channels
        hidden_sizes_Encoder2 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]  # final element = output number of channels from layer
        output_number_of_channels_Encoder2 = hidden_sizes_Encoder2[-1]
        number_of_channels_from_running_average_ouside_input_Encoder2 = Initial_CCL_number_of_output_channels*4  #the X4 is because of the shuffle
        ### Flags: ###
        self.flag_down2_use_outside_connection = True
        self.flag_down2_get_final_RGB_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_previous = False
        self.flag_down2_get_center_RGB_RunningAverage_current = False
        self.flag_down2_get_RawInputExplicit = False
        self.flag_down2_get_center_RNN_previous = False
        ### Allocate number of channels: ###
        #(1). From Upper Level:
        down2_number_of_input_channels_from_upper_layer = input_from_upper_level_number_of_channels_Encoder2;
        #(2). From Outside:
        down2_number_of_input_channels_from_outide = 0;
        if self.flag_down2_get_center_RNN_previous:
            down2_number_of_input_channels_from_outide += self.number_of_channels_LSTM_CCL_to_encoder_next_time
        if self.flag_down2_get_final_RGB_previous:
            down2_number_of_input_channels_from_outide += final_RGB_previous_number_of_channels * 1
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 1
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            down2_number_of_input_channels_from_outide += RGB_input_RunningAverage_number_of_channels * 1
        if self.flag_down2_get_RawInputExplicit:
            down2_number_of_input_channels_from_outide += RGB_input_number_of_channels * 1
        self.down2_number_of_input_channels_from_outide = down2_number_of_input_channels_from_outide
        self.down2_cross_connection_projection = Color_Space_Conversion_Layer(12*4, 3)
        self.down2 = UNET_Down_Fusion_General_V1(number_of_input_channels_from_upper_layer=down2_number_of_input_channels_from_upper_layer, #input_from_above + channels_from_center + raw_input_running_average_shuffled
                                                 number_of_input_channels_from_cross_connection=down2_number_of_input_channels_from_outide,  #TODO: maybe use a difference CCL for the encoder2
                                                 number_of_output_channels=hidden_sizes_Encoder2,
                                                 flag_use_final_projection_block=False,
                                                 number_of_output_channels_after_projection_block=hidden_sizes_Encoder2[-1],
                                                 flag_use_cross_connection=self.flag_down2_use_outside_connection,  # I should really call it something like "outer connection" or "outer information" because it's not a cross connection from another layer really or necessarily
                                                 flag_Sequential_or_RDB='sequential',
                                                 flag_sequential_dense=False,
                                                 flag_sequential_resnet=True,
                                                 flag_sequential_concat=False,
                                                 kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                                 strides=[1, 1],
                                                 dilations=[[1, 2*2, 4*2], [1, 2*2, 4*2]],
                                                 groups=[1, 1],
                                                 normalization_function=normalization_function,
                                                 activation_function=activation_function,
                                                 flag_downsample_strategy='DPP',
                                                 initialization_method='xavier',
                                                 flag_add_unshuffled_input_to_lower_level=False,
                                                 ##############################################   --  1-K-1 --(*+)---
                                                 ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                 flag_SuperBlock_SFT=[False, False, False],
                                                 flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                 flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                 flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                 flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                 flag_SuperBlock_SFT_shift=[False, False, False],
                                                 flag_SuperBlock_SFT_scale=[True, True, True],
                                                 ### Deformable Convolution: ###
                                                 flag_deformable_convolution=[False, False, False],
                                                 flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                 flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                 flag_deformable_convolution_modulation=[False, False, False],
                                                 flag_deformable_kernel_size=[5, 5, 5],
                                                 flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                 flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                 flag_deformable_same_on_all_channels=[True, True, True],
                                                 ### Deformable SFT: ###
                                                 flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                 flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                 flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                                 flag_deformable_SFT_shift=[False, False, False],
                                                 flag_deformable_SFT_scale=[False, False, False],
                                                 flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                 flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                 #####################################
                                                 flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                                 flag_super_cell_block_type=['131_collapse', '131_collapse'],  # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                                 )

        ###########################################################################################################################################################





        ###########################################################################################################################################################
        #### raw unshuffled RGB convmean2d RunningAverage output: ###
        ### Flags: ###
        self.flag_center_RGBRunningAverage_get_final_RGB_previous = False
        self.flag_center_RGBRunningAverage_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RGB_RunningAverage_input_channels = RGB_input_number_of_channels * (4**0);
        self.center_RGB_RunningAverage_outside_number_of_channels = 0;
        if self.flag_center_RGBRunningAverage_get_final_RGB_previous:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        if self.flag_center_RGBRunningAverage_get_RAW_RGB_current:
            self.center_RGB_RunningAverage_outside_number_of_channels += RGB_input_number_of_channels * (4**0)
        self.center_RGB_unshuffled_running_average = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                      input_size=self.center_RGB_RunningAverage_input_channels,
                                                      hidden_sizes=self.center_RGB_RunningAverage_input_channels,
                                                      n_layers=1,
                                                      kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                      normalization_function='none',
                                                      activation_function='none',
                                                      initialization_method='xavier',
                                                      flag_deformable_convolution=False,
                                                      flag_deformable_convolution_version='v1',
                                                      flag_deformable_convolution_before_or_after_main_convolution='before',
                                                      flag_deformable_convolution_modulation=False,
                                                      flag_deformable_same_on_all_channels=False)
        ### RunningAverage Features: ###
        self.flag_center_RunningAverageFeatures_get_final_RGB_previous = False
        self.center_features_RunningAverage_input_channels = self.down2.final_number_of_channels
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            self.center_features_RunningAverage_input_channels += final_RGB_previous_number_of_channels * (4**0)
        self.center_features_RunningAverage = Get_Memory_Unit(memory_unit_name='convmean2d_running_average',
                                                               input_size=self.center_features_RunningAverage_input_channels,
                                                               hidden_sizes=self.center_features_RunningAverage_input_channels,
                                                               n_layers=1,
                                                               kernel_sizes=[5], strides=1, dilations=1, groups=1,
                                                               normalization_function='none',
                                                               activation_function='none',
                                                               initialization_method='xavier',
                                                               flag_deformable_convolution=False,
                                                               flag_deformable_convolution_version='v1',
                                                               flag_deformable_convolution_before_or_after_main_convolution='before',
                                                               flag_deformable_convolution_modulation=False,
                                                               flag_deformable_same_on_all_channels=False)

        #### Center RNN: ####
        ### RNN Number of channels: ###
        input_from_upper_level_number_of_channels_Center = self.down2.final_number_of_channels
        number_of_layers_Center = 3;
        hidden_sizes_Center = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Center = hidden_sizes_Center[-1]
        self.hidden_sizes_Center = hidden_sizes_Center
        running_average_input = RGB_input_RunningAverage_number_of_channels * (4 ** 0)
        ### Flags: ###
        self.flag_center_RNN_get_final_RGB_previous = False
        self.flag_center_RNN_get_RGBRunningAverage_current = False
        self.flag_center_RNN_get_RAW_RGB_current = False
        ### Allocate number of channels: ###
        self.center_RNN_number_of_input_channels = self.down2.final_number_of_channels;
        if self.flag_center_RNN_get_final_RGB_previous:
            self.center_RNN_number_of_input_channels += final_RGB_previous_number_of_channels * (4**0)
        if self.flag_center_RNN_get_RAW_RGB_current:
            self.center_RNN_number_of_input_channels += RGB_input_number_of_channels * (4**0)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            self.center_RNN_number_of_input_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        # center_RNN.Conv_Layers.sub.module_list[0].full_basic_conv_block.flag_use_outside_conditional
        self.center_RNN = Sequential_Conv_Block_General(
                                                        number_of_input_channels=self.center_RNN_number_of_input_channels,
                                                        number_of_output_channels=[3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor],
                                                        kernel_sizes=[[5], [5], [5]],
                                                        strides=1,
                                                        dilations=[[1*4], [1*4], [1*4]],
                                                        groups=1,
                                                        padding_type='reflect',
                                                        normalization_function=normalization_function,
                                                        activation_function=activation_function,
                                                        mode='CNA',
                                                        initialization_method='xavier',
                                                        flag_dense=False,
                                                        flag_resnet=True,
                                                        flag_concat=False,
                                                        stack_residual_scale=1,
                                                        ##############################################   --  1-K-1 --(*+)---
                                                        ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                                        flag_SuperBlock_SFT=[False, False, False],
                                                        flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                                        flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                                        flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                                        flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                                        flag_SuperBlock_SFT_shift=[False, False, False],
                                                        flag_SuperBlock_SFT_scale=[True, True, True],
                                                        ### Deformable Convolution: ###
                                                        flag_deformable_convolution=[False, False, False],
                                                        flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                                        flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                                        flag_deformable_convolution_modulation=[False, False, False],
                                                        flag_deformable_kernel_size=[5, 5, 5],
                                                        flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                                        flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                                        flag_deformable_same_on_all_channels=[True, True, True],
                                                        ### Deformable SFT: ###
                                                        flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                                        flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                                        flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                                        flag_deformable_SFT_shift=[False, False, False],
                                                        flag_deformable_SFT_scale=[False, False, False],
                                                        flag_deformable_SFT_add_y_to_output=[False, False, False],
                                                        flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                                        #####################################
                                                        flag_single_cell_block_type=['simple', 'simple', 'simple'],
                                                        flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'],
                                                        )

        ### Number of channels further on: ###
        self.number_of_heads_on_top_of_basic_LSTM = 1 #including LSTM_flags output itself
        self.center_output_size = self.number_of_heads_on_top_of_basic_LSTM*hidden_sizes_Center[-1];
        self.number_of_channels_LSTM_CCL_to_decoder = self.center_output_size;
        self.Color_Conversion_Layer_center_to_decoder = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_decoder2 = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_decoder)
        self.Color_Conversion_Layer_center_to_encoder_next_time = Color_Space_Conversion_Layer(self.center_output_size, self.number_of_channels_LSTM_CCL_to_encoder_next_time)


        ############################################################################################################################################################





        ###########################################################################################################################################################
        #### Decoder2: ####
        ### Number of channels: ###
        input_from_lower_level_number_of_channels_Decoder3 = output_number_of_channels_Center
        number_of_layers_Decoder3 = 2;
        hidden_sizes_Decoder3 = [3 * 4 * 4 * channel_factor, 3 * 4 * 4 * channel_factor  , 3 * 4 * 4 * channel_factor]
        output_number_of_channels_Decoder1 = hidden_sizes_Decoder3[-1]
        ### Flags: ###
        self.flag_up2_use_cross_connection = True
        self.flag_up2_use_encoder_skip_connection = False
        self.flag_up2_get_RGBRunningAverage_current = False
        self.flag_up2_get_RunningAverageFeatures_current = False
        self.flag_up2_get_RGBRunningAverage_previous = False
        self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection = 'direct'
        self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection = 'direct'
        self.flag_up2_get_final_RGB_previous = False #TODO: later on add possibility to get it downsampled/unshuffled/only_intensity etc' FOR ALL FLAGS LIKE THIS!!@#
        self.flag_up2_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_center_RNN_previous = False
        self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection = 'cross_connection'
        self.flag_up2_get_RAW_RGB_current = False
        self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up2_lower_level_number_of_channels = self.number_of_channels_LSTM_CCL_to_decoder;
        self.up2_cross_connection_number_of_channels = 0
        # TODO: decider upon a strategy on how to upsample/input every possible input #
        #   (0). Encoder cross connection:
        if self.flag_up2_use_encoder_skip_connection:
            self.up2_cross_connection_number_of_channels += self.down2.final_number_of_channels
        #   (1). RNN previous:
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder;  #Need to upsample
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                self.up2_lower_level_number_of_channels += RGB_input_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_number_of_channels * (4**0)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up2_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                self.up2_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up2_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        if self.up2_cross_connection_number_of_channels == 0:
            self.flag_up2_use_cross_connection = False
        ### Define up2: ###
        self.up_concat2 = UNET_Up_General_V1(number_of_lower_level_channels=self.up2_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up2_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up2_cross_connection_number_of_channels,  # Insert shuffled running average input as cross connection... i could also choose to insert it directly from below
                                             number_of_output_channels=hidden_sizes_Decoder3,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=hidden_sizes_Decoder3[-1],
                                             flag_use_cross_connection=self.flag_up2_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3]],
                                             strides=1,
                                             dilations=[[1, 2*2, 4*2], [1, 2*2, 4*2]],
                                             groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='none',
                                             flag_add_unshuffled_input_to_upper_level=False,
                                             activation_function=activation_function,
                                             initialization_method=['xavier', 'xavier'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_SFT_convs_mix=['y', 'y', 'y'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )



        #### Decoder1: ####
        input_from_lower_level_number_of_channels_Decoder2 = self.up_concat2.final_number_of_channels
        number_of_layers_Decoder2 = 2;
        hidden_sizes_Decoder2 = [3 * 4 * channel_factor, 3 * 4 * channel_factor, 3]
        ### Flags: ###
        self.flag_up1_use_cross_connection = True
        self.flag_up1_use_encoder_skip_connection = False
        self.flag_up1_get_center_RNN_previous = False
        self.flag_up1_get_center_RNN_current = False
        self.flag_up1_get_center_RNN_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RGBRunningAverage_previous = False
        self.flag_up1_get_center_RGBRunningAverage_current = False
        self.flag_up1_get_center_RunningAverageFeatures_current = False
        self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_final_RGB_previous = False
        self.flag_up1_get_final_RGB_previous_direct_or_cross_connection = 'cross_connection'
        self.flag_up1_get_RAW_RGB_current = False
        self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection = 'cross_connection'
        ### Allocate number of channels: ###
        self.up1_lower_level_number_of_channels = self.up_concat2.final_number_of_channels
        self.up1_cross_connection_number_of_channels = 0
        #   (0). Encoder Cross-Connection:
        if self.flag_up1_use_encoder_skip_connection:
            self.up1_cross_connection_number_of_channels += self.down1.final_number_of_channels;
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (2). Features RunningAverage:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
            else:
                self.up1_cross_connection_number_of_channels += self.number_of_channels_LSTM_CCL_to_decoder
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_RunningAverage_number_of_channels * (4**0)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += final_RGB_previous_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += final_RGB_previous_number_of_channels
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                self.up1_lower_level_number_of_channels += RGB_input_number_of_channels * (4**0)
            else:
                self.up1_cross_connection_number_of_channels += RGB_input_number_of_channels
        if self.up1_cross_connection_number_of_channels == 0:
            self.flag_up1_use_cross_connection = False
        ### Define up1: ###
        self.up_concat1 = UNET_Up_General_V1(number_of_lower_level_channels=self.up1_lower_level_number_of_channels,
                                             number_of_lower_level_channels_after_upsample=self.up1_lower_level_number_of_channels,
                                             number_of_cross_connection_channels=self.up1_cross_connection_number_of_channels, #for upper level decoder i insert center output and RA output as "cross-connection"
                                             number_of_output_channels=hidden_sizes_Decoder2,
                                             flag_use_final_projection_block=False,
                                             number_of_output_channels_after_projection_block=3,
                                             flag_use_cross_connection=self.flag_up1_use_cross_connection,
                                             flag_Sequential_or_RDB='sequential',
                                             flag_sequential_dense=False,
                                             flag_sequential_resnet=True,
                                             flag_sequential_concat=False,
                                             stack_residual_scale=1,
                                             kernel_sizes=[[3, 3, 3], [3, 3, 3], [3]], strides=1, dilations=[[1, 2, 4], [1, 2, 4], [1]], groups=1,
                                             normalization_function=normalization_function,
                                             flag_upsample_method='none',
                                             activation_function=final_activation_function,
                                             initialization_method=['dirac', 'dirac', 'dirac'],
                                             ##############################################   --  1-K-1 --(*+)---
                                             ### FIRE/Super Block SFT Self-Interaction: ###   ------------|
                                             flag_SuperBlock_SFT=[False, False, False],
                                             flag_SuperBlock_SFT_use_outside_conditional=[True, True, True],
                                             flag_SuperBlock_SFT_same_on_all_channels=[False, False, False],
                                             flag_SuperBlock_SFT_base_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_SFT_convs_mix=['y', 'y', 'y'],  # 'x', 'y', 'xy'
                                             flag_SuperBlock_SFT_add_y_to_output=[False, False, False],
                                             flag_SuperBlock_SFT_shift=[False, False, False],
                                             flag_SuperBlock_SFT_scale=[True, True, True],
                                             ### Deformable Convolution: ###
                                             flag_deformable_convolution=[False, False, False],
                                             flag_deformable_convolution_version=['v3', 'v3', 'v3'],
                                             flag_deformable_convolution_before_or_after_main_convolution=['before', 'before', 'before'],  # 'before' / 'after'
                                             flag_deformable_convolution_modulation=[False, False, False],
                                             flag_deformable_kernel_size=[5, 5, 5],
                                             flag_deformable_number_of_deformable_groups=[-1, -1, -1],
                                             flag_deformable_number_of_channels_in_group1=[-1, -1, -1],
                                             flag_deformable_same_on_all_channels=[True, True, True],
                                             ### Deformable SFT: ###
                                             flag_deformable_SFT_use_outside_conditional=[False, False, False],
                                             flag_deformable_SFT_same_on_all_channels=[False, False, False],  ### The interactive shift/scale convs by default spits-out x.shape[1] number_of_channels....but maybe to save memory and parameters we want the same interaction on all channels
                                             flag_deformable_SFT_base_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_SFT_convs_mix=['x', 'x', 'x'],
                                             flag_deformable_SFT_shift=[False, False, False],
                                             flag_deformable_SFT_scale=[False, False, False],
                                             flag_deformable_SFT_add_y_to_output=[False, False, False],
                                             flag_deformable_for_each_sub_block_or_for_super_block=['super_block', 'super_block', 'super_block'],  # 'super_block' / 'sub_block'
                                             #####################################
                                             flag_single_cell_block_type=['simple', 'simple', 'simple'],  # 'simple'/ 'standard_residual'/ '131_residual'
                                             flag_super_cell_block_type=['131_collapse', '131_collapse', '131_collapse'], # 'concat' / '131' / '131_collapse' / 'concat_standard_residual' / '131_residual' / '131_collapse_residual'
                                             )

        # self.unshuffle1 = UnshufflePixels(2);
        # self.unshuffle2 = UnshufflePixels(4);
        # self.shuffle1 = ShufflePixels(2);
        # self.shuffle2 = ShufflePixels(4);
        # self.upsample1 = nn.UpsamplingBilinear2d(scale_factor=2)
        # self.upsample2 = nn.UpsamplingBilinear2d(scale_factor=4)
        self.upsample1 = Identity_Layer()  #No change in sizes
        self.upsample2 = Identity_Layer()  #No change in sizes
        self.unshuffle1 = Identity_Layer()
        self.unshuffle2 = Identity_Layer()
        self.shuffle1 = Identity_Layer()
        self.shuffle2 = Identity_Layer()

        self.center_RGB_RunningAverage_output_previous = None
        self.center_RNN_output_to_encoder_previous = None
        self.center_RNN_output_to_decoder_previous = None
        self.final_output_previous = None
        self.final_output_previous_warped = None

        self.AvgPool2d = Identity_Layer()  #No change in sizes
        ##########################################################################################################################################################

    def reset_hidden_states(self):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_hidden_states'):
                current_layer.reset_hidden_states();

    def reset_or_detach_hidden_states(self, reset_flags_list):
        for current_layer in self.children():
            if hasattr(current_layer, 'reset_or_detach_hidden_states'):
                current_layer.reset_or_detach_hidden_states(reset_flags_list);

    def hidden_states_to_device(self, device):
        for current_layer in self.children():
            if hasattr(current_layer, 'hidden_states_to_device'):
                current_layer.hidden_states_to_device(device);

    def forward(self, x, reset_flags_list=[0]):
        ### If i don't have one already then create an instance of TVNet for optical flow of RGB inputs/outputs: ###
        if self.TVNet_layer is None:
            self.TVNet_layer = get_TVNet_instance(x, number_of_iterations=self.TVNet_number_of_iterations, number_of_pyramid_scales=self.TVNet_number_of_pyramid_scales, device=x.device, flag_trainable=False)

        ### Color Space Conversion: ###
        # x = self.Color_Conversion_Layer(x);

        ### Unshuffled Input: ###
        unshuffled_input1 = self.unshuffle1(x)
        unshuffled_input2 = self.unshuffle2(x);


        # ### Previous RNN Outputs: ###
        # self.center_RGB_RunningAverage_output_previous = self.center_RGB_unshuffled_running_average.hidden_states[-1]
        # self.center_RNN_output_previous = self.center.hidden_H[-1]


        #############
        ### UNET: ###
        #############
        ### Preproces (Initialize if needed) previous RNN outputs according to reset_flags_list: ###
        # TODO: generalize this as a function within the RNNs which goes like: create_initial_hidden_state(input_tensor, reset_flags_list)
        if reset_flags_list[0]==1:
            #Zero/Initialize at start of batch:
            self.center_RGB_RunningAverage_output_previous = unshuffled_input2;
            self.center_RNN_output_to_encoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_encoder_next_time, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.center_RNN_output_to_decoder_previous = torch.zeros(x.shape[0], self.number_of_channels_LSTM_CCL_to_decoder, int(x.shape[2]/4), int(x.shape[3]/4)).to(x.device)
            self.final_RGB_output_previous = x; #TODO: understand whether i should use ._copy() or is this enough
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous = x.mean(dim=1, keepdim=True)
            ### Optical Flow Related: ###
            self.final_RGB_output_previous_warped = x;
            if self.flag_input_raw_intensity_instead_of_rgb:
                self.final_RGB_output_previous_warped = x.mean(dim=1, keepdim=True)
            self.delta_x = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
            self.delta_y = torch.zeros(x.shape[0], 1, x.shape[2], x.shape[3])
        if reset_flags_list[0] == 3:
            self.center_RNN_output_to_encoder_previous = self.center_RNN_output_to_encoder_previous.detach()
            self.center_RNN_output_to_decoder_previous = self.center_RNN_output_to_decoder_previous.detach()
            self.center_RGB_RunningAverage_output_previous = self.center_RGB_RunningAverage_output_previous.detach()
            self.final_RGB_output_previous = self.final_RGB_output_previous.detach()
            # ### Optical Flow Related - USE TVNET!!!!: ###
            # self.delta_x, self.delta_y, x2_warped = self.TVNet_layer(x, self.final_RGB_output_previous)
            # self.delta_x = self.delta_x.detach()
            # self.delta_y = self.delta_y.detach()
            # self.final_RGB_output_previous_warped = x2_warped



        ### Shuffle / Upample Previous RNN Outputs: ##
        #(1). Detach Last Final Output in order to prevent memory overload and because it's probably not that necessary???:
        final_RGB_output_previous = self.final_RGB_output_previous
        final_RGB_output_previous_unshuffled1 = self.unshuffle1(final_RGB_output_previous)
        final_RGB_output_previous_unshuffled2 = self.unshuffle2(final_RGB_output_previous)
        #(2). Assign meaningful variable names to whole U-Net memories:
        #   (2.1). Raw Input Running Average (probably later on wrapped + some sort of T map (similar to TNR by the way)):
        center_RGB_RunningAverage_output_previous_shuffled1 = self.shuffle1(self.center_RGB_RunningAverage_output_previous)
        center_RGB_RunningAverage_output_previous_shuffled2 = self.shuffle2(self.center_RGB_RunningAverage_output_previous)
        #   (2.2). Center LSTM output derived outputs (1 to encoder & 1 to decoder after two different CCL):
        center_RNN_output_to_encoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_encoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_encoder_previous)
        center_RNN_output_to_decoder_previous_upsampled1 = self.upsample1(self.center_RNN_output_to_decoder_previous)
        center_RNN_output_to_decoder_previous_upsampled2 = self.upsample2(self.center_RNN_output_to_decoder_previous)
        #(3). DownSample Input and Previouse-Output RGB Using AvgPool2d:
        x_intensity = x.mean(dim=1, keepdim=True)

        ### RunningAverage RGB: ###
        center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        center_RGB_RunningAverage_output_shuffled1 = self.shuffle1(center_RGB_RunningAverage_output)  # running average is full resolution unshuffled for now so i need to shuffle it back (later on i will probably use bilinear upsample or something)
        center_RGB_RunningAverage_output_shuffled2 = self.shuffle2(center_RGB_RunningAverage_output)

        # ### PCD Feature Extraction and Alignment Module: ###
        # PCD_output_reference_previous = self.PCD_Extract_and_Align_Module(x_intensity, final_RGB_output_previous)  # self.final_RGB_output_previous is also Intensity!
        # PCD_output_reference_reference = self.PCD_Extract_and_Align_Module(x_intensity, x_intensity)

        # ### TSA Fusion Module: ###
        # #(1). Combine PCD_reference_previous & PCD_reference_reference to get TSA_Fusion_Module inputs which does Spatio-Temporal Weighing & Mixture of Features:
        # TSA_input = torch.cat([PCD_output_reference_previous.unsqueeze(1),PCD_output_reference_reference.unsqueeze(1)],dim=1)  #[B,C,H,W] -> [B,N,C,H,W]
        # #(2). TSA Module:
        # TSA_output = self.TSA_Fusion_Module(TSA_input)


        #############################################################################
        # ### Conditional Network On Concatenated-Features Input&Output RGB(!): ###
        # y_cell_conditional_input_level1 = torch.cat([x_intensity, final_RGB_output_previous],dim=1)
        # y_cell_conditional_input_level2 = torch.cat([unshuffled_input1, final_RGB_output_previous_unshuffled1],dim=1)
        # y_cell_conditional_input_center = torch.cat([unshuffled_input2, final_RGB_output_previous_unshuffled2],dim=1)
        # ### SFT is residual between current and last output: ###
        # y_cell_conditional_input_level1 = torch.abs(x_intensity-final_RGB_output_previous)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Previous Intensity As Conditional: ###
        # y_cell_conditional_input_level1 = final_RGB_output_previous
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Conditional Network On Each Feature Seperately Input&Output RGB(!): ###
        # x_intensity_downsampled1 = self.AvgPool2d(x_intensity)
        # x_intensity_downsampled2 = self.AvgPool2d(x_intensity_downsampled1)
        # final_RGB_output_previous_downsampled1 = self.AvgPool2d(final_RGB_output_previous)
        # final_RGB_output_previous_downsampled2 = self.AvgPool2d(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_level1_1 = self.Conditionals_Network(x_intensity)
        # y_cell_conditional_input_level2_1 = self.Conditionals_Network(x_intensity_downsampled1)
        # y_cell_conditional_input_center_1 = self.Conditionals_Network(x_intensity_downsampled2)
        # y_cell_conditional_input_level1_2 = self.Conditionals_Network(final_RGB_output_previous)
        # y_cell_conditional_input_level2_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled1)
        # y_cell_conditional_input_center_2 = self.Conditionals_Network(final_RGB_output_previous_downsampled2)
        # y_cell_conditional_input_level1 = torch.cat([y_cell_conditional_input_level1_1, y_cell_conditional_input_level1_2], dim=1)
        # y_cell_conditional_input_level2 = torch.cat([y_cell_conditional_input_level2_1, y_cell_conditional_input_level2_2], dim=1)
        # y_cell_conditional_input_center = torch.cat([y_cell_conditional_input_center_1, y_cell_conditional_input_center_2], dim=1)
        # ### Use TSA Output As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([TSA_output],dim=1);
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use Conditional Network as feature extractors: ###
        # y_cell_conditional_input_level1 = torch.cat([self.Conditionals_Network(x_intensity), self.Conditionals_Network(final_RGB_output_previous)], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network2(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        # ### Use PCD Outputs As Conditionals: ###
        # y_cell_conditional_input_level1 = torch.cat([PCD_output_reference_previous, PCD_output_reference_reference], dim=1);
        # y_cell_conditional_input_level1 = self.Conditionals_Network(y_cell_conditional_input_level1)
        # y_cell_conditional_input_level2 = self.AvgPool2d(y_cell_conditional_input_level1)
        # y_cell_conditional_input_center = self.AvgPool2d(y_cell_conditional_input_level2)
        ### NO Conditionals: ###
        y_cell_conditional_input_level1 = None
        y_cell_conditional_input_level2 = None
        y_cell_conditional_input_center = None
        #############################################################################


        ### Encoder1: ###
        # self.flag_down1_get_final_RGB_previous = True;
        # self.flag_down1_get_center_RGB_RunningAverage_previous = True
        # self.flag_down1_get_center_RNN_previous = True;
        ###
        # encoder1_input = torch.cat([x, final_RGB_output_previous, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)  # regular input = raw_RGB_input + last_final_RGB_output +  RGB_running_average
        # encoder1_outside_connection = torch.cat([center_RNN_output_to_encoder_previous_upsampled2], dim=1);  # outside connection = lstm_output
        encoder1_input = x
        encoder1_outside_connection = None
        if self.flag_down1_get_final_RGB_previous:
            encoder1_input = torch.cat([encoder1_input, final_RGB_output_previous], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_previous:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        if self.flag_down1_get_center_RGB_RunningAverage_current:
            encoder1_input = torch.cat([encoder1_input, center_RGB_RunningAverage_output_shuffled2], dim=1)
        if self.flag_down1_get_center_RNN_previous:
            if encoder1_outside_connection is None: encoder1_outside_connection = center_RNN_output_to_encoder_previous_upsampled2
            else:
                encoder1_outside_connection = torch.cat([encoder1_outside_connection, center_RNN_output_to_encoder_previous_upsampled2], dim=1)
        ### Adding PCD output: ###
        encoder1_input = torch.cat([encoder1_input],dim=1)
        # print(y_cell_conditional_input_level1.shape)
        encoder1, maxpool1 = self.down1(x=encoder1_input, outside_connection_input=encoder1_outside_connection, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Encoder2: ###
        encoder2_input = encoder1;
        encoder2_outside_connection = None
        ###
        if self.flag_down2_get_final_RGB_previous:
            encoder2_input = torch.cat([encoder2_input, final_RGB_output_previous_unshuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_previous:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        if self.flag_down2_get_center_RGB_RunningAverage_current:
            encoder2_input = torch.cat([encoder2_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
        if self.flag_down2_get_RawInputExplicit:
            if encoder2_outside_connection is None: encoder2_outside_connection = unshuffled_input1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, unshuffled_input1], dim=1)
        if self.flag_down2_get_center_RNN_previous:
            if encoder2_outside_connection is None: encoder2_outside_connection = center_RNN_output_to_encoder_previous_upsampled1
            else:
                encoder2_outside_connection = torch.cat([encoder2_outside_connection, center_RNN_output_to_encoder_previous_upsampled1], dim=1)
        encoder2, maxpool2 = self.down2(x=encoder2_input, outside_connection_input=encoder2_outside_connection, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)


        #### Center: ####
        # self.flag_center_RNN_get_final_RGB_previous = True
        # self.flag_center_RNN_get_RGBRunningAverage_current = True
        # self.flag_center_RNN_get_RAW_RGB_current = False
        ###
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RNN_input = torch.cat([maxpool2, final_RGB_output_previous_unshuffled2, center_RGB_RunningAverage_output], dim=1)
        # center_RNN_output = self.center_RNN(center_RNN_input, reset_flags_list)
        # combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.1). Current RNN Outputs:
        #       (2.1.1). Running Average (RA):
        #           (2.1.1.1). Get Running Average Warped According To Optical Flow.... or maybe simple replace hidden_state with last clean image?!?!?!?
        # TODO: implement!!!
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = warp_tensor(self.center_RGB_unshuffled_running_average.hidden_H[0], self.delta_x, self.delta_y)
        # self.center_RGB_unshuffled_running_average.hidden_H[0] = self.final_RGB_output_previous_warped
        #           (2.1.1.2). Pass Raw RGB Unshuffled Input Into Optical Flow:
        #TODO: make sure that if i don't use it no memory is needed!!!.... i switched it to =unshuffled_input2 for now...
        # center_RGB_RunningAverage_output = self.center_RGB_unshuffled_running_average(unshuffled_input2, reset_flags_list)
        # center_RGB_RunningAverage_output = unshuffled_input2;
        #       (2.1.2). LSTM:
        #### RNN: ####
        center_RNN_input = encoder2
        if self.flag_center_RNN_get_final_RGB_previous:
            center_RNN_input = torch.cat([center_RNN_input,final_RGB_output_previous_unshuffled2], dim=1)
        if self.flag_center_RNN_get_RAW_RGB_current:
            center_RNN_input = torch.cat([center_RNN_input, unshuffled_input2], dim=1)
        if self.flag_center_RNN_get_RGBRunningAverage_current:
            center_RNN_input = torch.cat([center_RNN_input, center_RGB_RunningAverage_output], dim=1)
        ### Pass Inputs through center RNN & RunningAverage Layers: ###
        center_RNN_output = self.center_RNN(center_RNN_input, y_cell_conditional=y_cell_conditional_input_center, y_deformable_conditional=None)
        combined_center_RNN_output = torch.cat([center_RNN_output], dim=1)
        #   (2.2). Color-Conversion-Layer for lstm output to reduce large number of channels:
        center_RNN_output_to_decoder_current = self.Color_Conversion_Layer_center_to_decoder(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        center_RNN_output_to_encoder_next_time = self.Color_Conversion_Layer_center_to_encoder_next_time(combined_center_RNN_output)  #WHAT THE FUCK? THERE WAS .DETACH() HERE!#!@!#
        #   (2.3). Assign previous outputs for NEXT TIME:
        self.center_RGB_RunningAverage_output_previous = center_RGB_RunningAverage_output
        self.center_RNN_output_to_encoder_previous = center_RNN_output_to_encoder_next_time.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        self.center_RNN_output_to_decoder_previous = center_RNN_output_to_decoder_current.detach()  #NOTICE!!! - i use detach because i'm not using this output and this is no longer an RNN
        #   (2.4). Upsample Current RNN Outputs:
        center_RNN_output_to_decoder_upsampled1 = self.upsample1(center_RNN_output_to_decoder_current)
        center_RNN_output_to_decoder_upsampled2 = self.upsample2(center_RNN_output_to_decoder_current)

        #### Running Average On Features: ###
        center_RunningAverage_features_input = maxpool2;
        if self.flag_center_RunningAverageFeatures_get_final_RGB_previous:
            center_RunningAverage_features_input = torch.cat([center_RunningAverage_features_input, final_RGB_output_previous_unshuffled2],dim=1)
        center_RunningAverage_features_output = self.Color_Conversion_Layer_center_to_decoder2(self.center_features_RunningAverage(center_RunningAverage_features_input))
        center_RunningAverage_features_output_upsampled1 = self.upsample1(center_RunningAverage_features_output)
        center_RunningAverage_features_output_upsampled2 = self.upsample2(center_RunningAverage_features_output)


        ### Decoder2: ###
        decoder2_input = center_RNN_output_to_decoder_current;
        decoder2_cross_connection = None;
        ###
        if self.flag_up2_use_encoder_skip_connection:
            if decoder2_cross_connection is None: decoder2_cross_connection = encoder2
            else:
                decoder2_cross_connection = torch.cat([decoder2_cross_connection, encoder2], dim=1);
        #   (5). RGB RunningAverage current:
        if self.flag_up2_get_RGBRunningAverage_current:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RGB_RunningAverage_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RGB_RunningAverage_output_shuffled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_shuffled1], dim=1)
        #   (6). Features RunningAverage current:
        if self.flag_up2_get_RunningAverageFeatures_current:
            if self.flag_up2_get_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, center_RunningAverage_features_output], dim=1)
            else:
                if decoder2_cross_connection is None:
                    decoder2_cross_connection = center_RunningAverage_features_output_upsampled1
                else:
                    decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RunningAverage_features_output_upsampled1], dim=1)
        #   (1). RNN previous
        if self.flag_up2_get_center_RNN_previous:
            if self.flag_up2_get_center_RNN_prevous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RNN_output_to_decoder_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RNN_output_to_decoder_previous_upsampled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RNN_output_to_decoder_previous_upsampled1], dim=1)
        #   (2). Final RGB previous:
        if self.flag_up2_get_final_RGB_previous:
            if self.flag_up2_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, final_RGB_output_previous_unshuffled2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = final_RGB_output_previous_unshuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, final_RGB_output_previous_unshuffled1], dim=1)
        #   (3). RAW Input RGB current:
        if self.flag_up2_get_RAW_RGB_current:
            if self.flag_up2_get_RAW_RGB_current_direct_or_cross_connection:
                decoder2_input = torch.cat([decoder2_input, unshuffled_input2], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = unshuffled_input1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, unshuffled_input1], dim=1)
        #   (4). RGB RunningAverage previous:
        if self.flag_up2_get_RGBRunningAverage_previous:
            if self.flag_up2_get_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder2_input = torch.cat([decoder2_input, self.center_RGB_RunningAverage_output_previous], dim=1)
            else:
                if decoder2_cross_connection is None:
                     decoder2_cross_connection = center_RGB_RunningAverage_output_previous_shuffled1
                else:
                     decoder2_cross_connection = torch.cat([decoder2_cross_connection, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
        ### Decoder2: ###
        decoder2 = self.up_concat2(input_cross_connection=decoder2_cross_connection, input_low_layer=decoder2_input, y_cell_conditional=y_cell_conditional_input_level2, y_deformable_conditional=None)
                                                                    #(*). NOTE!!!...there is one very important different between lower layer inputs and cross-connection: SPATIAL SIZE....
                                                                                                                            #     the layers from input_low_layer go in with smaller size AND THE LAYER ITSELF CHOOSES HOW TO UPSAMPLE THEM!!!!


        ### Decoder1: ###
        decoder1_input = decoder2;
        decoder1_cross_connection = None
        ### Allocate number of channels: ###
        #   (6). Encoder Cross Connection:
        if self.flag_up2_use_encoder_skip_connection:
            if decoder1_cross_connection is None: decoder1_cross_connection = encoder1
            else:
                decoder1_cross_connection = torch.cat([decoder1_cross_connection, encoder1], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RGBRunningAverage_current:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_shuffled2], dim=1)
        #   (3). RunningAverage current:
        if self.flag_up1_get_center_RunningAverageFeatures_current:
            if self.flag_up1_get_center_RunningAverageFeatures_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RunningAverage_features_output_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                    decoder1_cross_connection = center_RunningAverage_features_output_upsampled2
                else:
                    decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RunningAverage_features_output_upsampled2], dim=1)
        #   (2). RNN current:
        if self.flag_up1_get_center_RNN_current:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RNN_output_to_decoder_upsampled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_upsampled2], dim=1)
        #   (1). RNN previous:
        if self.flag_up1_get_center_RNN_previous:
            if self.flag_up1_get_center_RNN_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input,center_RNN_output_to_decoder_previous_upsampled1] , dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RNN_output_to_decoder_previous_upsampled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RNN_output_to_decoder_previous_upsampled2], dim=1)
        #   (4). RunningAverage previous:
        if self.flag_up1_get_center_RGBRunningAverage_previous:
            if self.flag_up1_get_center_RGBRunningAverage_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, center_RGB_RunningAverage_output_previous_shuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = center_RGB_RunningAverage_output_previous_shuffled2
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, center_RGB_RunningAverage_output_previous_shuffled2], dim=1)
        #   (5). Final RGB previous:
        if self.flag_up1_get_final_RGB_previous:
            if self.flag_up1_get_final_RGB_previous_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, final_RGB_output_previous_unshuffled1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = final_RGB_output_previous
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, final_RGB_output_previous], dim=1)
        #   (6). RAW RGB current:
        if self.flag_up1_get_RAW_RGB_current:
            if self.flag_up1_get_RAW_RGB_current_direct_or_cross_connection == 'direct':
                decoder1_input = torch.cat([decoder1_input, unshuffled_input1], dim=1)
            else:
                if decoder1_cross_connection is None:
                     decoder1_cross_connection = x
                else:
                     decoder1_cross_connection = torch.cat([decoder1_cross_connection, x], dim=1)
        ### Decoder1: ###
        decoder1 = self.up_concat1(input_cross_connection=decoder1_cross_connection, input_low_layer=decoder1_input, y_cell_conditional=y_cell_conditional_input_level1, y_deformable_conditional=None)


        ### Assign Final Output (Detached for now!!!): ###
        # self.final_RGB_output_previous = decoder1.detach()  #NOTICE: I DELETED .detach()
        self.final_RGB_output_previous = decoder1  #NOTICE: I DELETED .detach()
        if self.flag_input_raw_intensity_instead_of_rgb:
            self.final_RGB_output_previous = self.final_RGB_output_previous.mean(dim=1, keepdim=True)

        ### Add Input Residual If Wanted: ###
        if self.UNET_Residual:
            decoder1 += x;

        return decoder1
#################################################################################################################################################################################################################################################################################################################################################################################################################################################################################











